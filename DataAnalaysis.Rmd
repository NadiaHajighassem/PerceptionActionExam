---
title: "Data analysis"
author: "Nadia and Katharina"
output:
  html_document:
      toc: yes
      number_sections: no
      toc_float: yes
      theme: united
      highlight: espresso
      css: '../../varia/standard.css'
geometry: margin=1in
knit: (function(inputFile, encoding) {
  browseURL(
    rmarkdown::render(
      inputFile,
      encoding = encoding,
      output_dir = "html.file",
      output_file = "DataAnalysis.html"))})
---

```{r setuP}
## Setup chunk
knitr::opts_chunk$set(echo = TRUE, include = TRUE, message = FALSE, warning = FALSE)
```

Here i am just loading the packages and setting up our working directory. I am also specifying, which group we are looking at.

```{r loading packages}
pacman::p_load(
  "XML",
  "tidyverse",
  "fs",
  "assertthat",
  "stringi",
  "dtw",
  "RTransferEntropy",
  "signal",
  "conflicted",
  "Rcpp",
  "future",
  "fastICA"
)

## Making sure we are in the right directory
wd <- getwd()
if (basename(wd) != "PerceptionActionExam") {
  setwd("./PerceptionActionExam")
}

# set the directory for the data
# note, path_home() will return the path to your home directory
# your home directory is the one that contains your documents, downloads, etc.
data_dir <- path_home() %>% 
  path("Documents", "GitHub", "PerceptionActionExam", "data", "tsvs") ## Nadia's path

#data_dir <- path_home() %>% 
 # path("Desktop","UNI", "Perception & Action", "Exam", "data", "tsvs") ## Katharina's path

# set your study group
group_number <- 8

# The available conditions and their start and end frame indices
# to use the whole file, just set the value for the condition to c(NA, NA)
conditions <- list(
  jointlead = c(NA, NA),
  followlead = c(NA, NA),
  leadfollow = c(NA, NA),
  custom = c(NA, NA)
)

# Calling functions
source("Functions.R")
```

And so, some more boring stuff...This is just getting the labels so we can make sure that the tracked markers match up with what we expected, really, this shouldn't go wrong, but if you don't check this kind of thing you'll end up scratching your head later wondering why everything broke.

```{r}
# load the labels from the XML file

# load the XML file
xmlfile <- xmlParse("PerAct23_LabelList.xml")

# get the labels, which are in the following format:
# <QTM_Label_List_Ver_1.00>
#     <Trajectories>
#         <Trajectory>
#             <Name>A_head_top</Name>
#             <Color R="0" G="147" B="0"/>
#         </Trajectory>
#     </Trajectories>
# </QTM_Label_List_Ver_1.00>

# get the trajectory names
traj_names <- xpathSApply(xmlfile, "//Trajectory/Name", xmlValue)

# get the trajectory colors
traj_colors <- xpathSApply(xmlfile, "//Trajectory/Color", xmlAttrs)

# convert the colors to hex
traj_colors <- rgb(
  as.numeric(traj_colors[1,]),
  as.numeric(traj_colors[2,]),
  as.numeric(traj_colors[3,]),
  alpha = 255,
  maxColorValue = 255
)


# combine the names and colors into a data frame
traj_labels <- data.frame(
  traj_names,
  traj_colors,
  stringsAsFactors = FALSE
)

rm(xmlfile, traj_names, traj_colors)
```

Finally loading in data hehehe (insert elmo meme with fire in the background)

Aditionally, this code is transforming data from a wide format, where each marker's x, y, and z coordinates are in separate columns, to a long format where all the coordinates are in a single column. It then adds more information about each observation (subject, axis, and marker) before pivoting it back to a wide format.

```{r}
## this loads in all the files
#traj_files <- fs::dir_ls(data_dir, regexp = "\\.tsv$")
```

```{r 'Load Trajectory Data'}
# load the trajectory data, we want all TSVs with the group number in the name

# get the files
traj_files <- fs::dir_ls(data_dir, regexp = paste0("group", group_number, "_.*\\.tsv$"))


# load the data
traj_data <- lapply(traj_files, process_qtm_tsv) ## This basically reads in the data 


# first we need to add the condition and group to each data frame
traj_data <- lapply(traj_data, function(x) {
  x$data$condition <- x$metadata$condition
  x$data$group <- paste0("group", group_number)
  return(x)
})

# now we can combine the data
traj_data <- do.call(bind_rows, lapply(traj_data, `[[`, "data")) ## This basically combines all the lists into one dataframe

# make the condition and group factors
traj_data$condition <- factor(traj_data$condition)
traj_data$group <- factor(traj_data$group)

# take a look at the data
head(traj_data)

# let's also make sure that all of the marker names are the same
# we can do this by getting the unique marker names
marker_names <- unique(traj_data %>% select(contains("_x")) %>% names() %>% stri_replace_last_regex("_x", ""))

# now we can check that all of the marker names are the same
assertthat::assert_that(
  all(marker_names == traj_labels$traj_names),
  msg = "Not all marker names are the same"
)

# let's make the data long format so we can easily group by subject or marker
traj_data <- traj_data %>% 
  pivot_longer(
    cols = contains("_x") | contains("_y") | contains("_z"),
    cols_vary = "slowest",
    names_to = "marker",
    values_to = "value"
  ) %>%
  mutate(
    subject = stri_replace_first_regex(marker, "^([AB])_.*", "$1"),
    axis = stri_extract_last_regex(marker, "[xyz]$"),
    marker = stri_replace_first_regex(marker, "^[AB]_([a-zA-Z_]+)_[xyz]$", "$1")
  )


# move axes to columns
traj_data <- traj_data %>% 
  pivot_wider(
    names_from = axis,
    values_from = value
  )

# Making sure that we have all of the different markers HEHEHEEH HI KAT
unique(traj_data$marker)

#traj_data$marker <- factor(traj_data$marker, levels = marker_names) ## i cant remember why this is here, but i think it is important later. 
```

# Trim the trajectories

Here's where you cut the start and ends off of the trajectores, this is useful for example when you know that there's some setup time or a delay from recording start to end, or if you just want to look at a specific section of the data.

If you set up the conditions correctly in the setup section, then you can just run this cell and it will crop the data for you.

```{r 'Crop trajectory data'}

# We want to crop the data for each condition
# let's get all the recorded conditions
recorded_conditions <- unique(traj_data$condition)
for (cond in recorded_conditions) {
  # get the start and end frame for the condition
  start_frame <- conditions[[cond]][1]
  if (is.na(start_frame)) start_frame <- 1
  end_frame <- conditions[[cond]][2]
  if (is.na(end_frame)) end_frame <- max(traj_data[traj_data$condition == cond, "index"])
  # crop the data
  traj_data <- traj_data %>% 
    dplyr::filter(condition == cond & index >= start_frame & index <= end_frame | condition != cond)
}

# select min and max indices by condition
traj_data %>% 
  group_by(condition) %>% 
  summarise(
    min_index = min(index),
    max_index = max(index))

# report observations per condition
traj_data %>% 
  group_by(condition, subject, marker) %>% 
  summarise(
    n_obs = n()
  ) %>%
  print(n = 100)
```


```{r}
## Filtering out custom condition
traj_data <- traj_data %>% 
  dplyr::filter(condition %in% c("leadfollow", "followlead")) ## a bit confused why this works

## Checking to see if the filtering worked :)
traj_data %>%
  distinct(condition)
```



# Inspect the data

I've included some ways here of inspecting the data to see if there are any obvious problems.

## Check for large jumps in trajectory data

This is a simple check to see if there are any large jumps in the data, this can indicate that there are some label errors (e.g. label `hand_left` became label `hand_right`), or that the data is just bad.

```{r 'Check for large jumps in trajectory data'}
# we want to check for large jumps in the data
# this indicates potential label errors

# we will do this by calculating the distance between each marker for each time point
# of course, by condition


# calculate the euclidean distance between each marker (using x, y, z)
# we will do this by condition, subject, marker and axis
marker_distances <- traj_data %>% 
  group_by(condition, subject, marker) %>%
  arrange(index) %>%
  mutate(
    diff_x = x - dplyr::lag(x, 1),
    diff_y = y - dplyr::lag(y, 1),
    diff_z = z - dplyr::lag(z, 1)
  )
  

# now we can calculate the euclidean distance per maker
marker_distances <- marker_distances %>% 
  mutate(
    euclidean_distance = sqrt(diff_x^2 + diff_y^2 + diff_z^2)
  )

# now we can plot the series for each marker, and see if anything stands out
marker_distances %>% 
  ggplot(aes(x = index, y = euclidean_distance)) +
  geom_line(aes(color = factor(marker)), linewidth=1.25) +
  theme_minimal() +
  facet_wrap(c(~condition, ~subject)) +
  labs(
    x = "Index",
    y = "Euclidean distance",
    title = "Euclidean distance from previous frame by marker"
  )

# save the plot
ggsave(
  filename = "./results/euclidean_distance_by_marker.png",
  width = 10,
  height = 10,
  units = "cm",
  dpi = 300
)

```

# Check for NAs

Specifically, this checks how much of a given trajectory is `NA` values and how long the longest sequence of `NA` values is. This can be useful for deciding whether to discard a marker or not.

*Remember, you'll want to make sure that both subject A and B have at least one good quality matching marker.*

```{r 'Get information about NAs'}

# get NAs counts
# by condition, marker, subject and axis
nas_cond_marker <- traj_data %>%
  group_by(condition, subject, marker) %>%
  summarise_at(
    vars(x, y, z),
    ~ sum(is.na(.))
  )

# plot to check if it is acceptable
nas_cond_marker %>% 
  ggplot(aes(x = marker, y = x, fill=marker, group=subject)) +
  geom_col(
    show.legend = FALSE
  ) +
  coord_flip() +
  theme_minimal() +
  facet_wrap(c(~subject, ~condition)) +
  labs(
    x = "Marker",
    y = "NA count",
    title = "NA count by marker"
  )

ggsave(
  filename = "./results/NA_count_by_marker.png",
  width = 10,
  height = 10,
  units = "cm",
  dpi = 300
)


# Now we can get the longest sequence of NAs for each marker
longest_na_seq <- traj_data %>% 
  group_by(condition, subject, marker) %>%
  summarise_at(
    vars(x, y, z),
    ~ max(rle(is.na(.))$lengths)
  )

# plot to check if it is acceptable
longest_na_seq %>% 
  ggplot(aes(x = marker, y = x, fill=marker, group=subject)) +
  geom_col(
    show.legend = FALSE
  ) +
  coord_flip() +
  theme_minimal() +
  facet_wrap(c(~subject, ~condition)) +
  labs(
    x = "Marker",
    y = "Longest NA sequence",
    title = "Longest NA sequence by marker"
  )

ggsave(
  filename = "./results/longest_na_sequence_by_marker.png",
  width = 10,
  height = 10,
  units = "cm",
  dpi = 300
)

```

## Note to self: This is probably, where will have to look at the different groups and check for NA's aka markers that haven't been labeled. Hopefully there isn't too many NA's and we can go straight to the analysis part.

TL:DR; There is a problem with group 7 and 10 There is a problem with loading all the data files in. I will continue with data analysis, so we can ask Peter --------------------------------------------------------

# Pick your poison

You can choose one or more markers and put them in the `markers_of_interest` variable below. This will then be used for the rest of the analysis.

```{r 'Choose markers of interest'}
# we want to choose the markers of interest
# we will choose the following markers:
# - {A,B}_head_top
# - {A,B}_hand_right
# you may of course choose different markers, or if those ones were
# particularly bad, you should select others

# get the markers of interest
markers_of_interest <- c(
  "hand_right"
)

# now we can select the markers of interest
selected_traj_data <- traj_data %>% 
  dplyr::filter(marker %in% markers_of_interest)

```

# Gap filling

Now that we're left with mainly the data we want to work with, we can do some gap filling to eliminate any `NA` values, just beware that it can't fill NAs at the start or end of the data.

```{r 'Gap fill trajectory data'}
# we are only going to do a linear gap fill, it's not elegant, but it works
# we will do this for each marker x, y, and z

# choose a single marker from markers_of_interest for plotting purposes only
sel_idx = 1

# plot a single marker's x, y, and z values before and after gap filling
selected_traj_data %>%
  dplyr::filter(marker == markers_of_interest[sel_idx]) %>%
  ggplot(aes(x = elapsed_time, y = x, color = subject)) +
  geom_line() +
  theme_minimal() +
  facet_wrap(c(~condition)) +
  labs(
    x = "Elapsed time",
    y = "Marker X position",
    title = paste("Marker", markers_of_interest[sel_idx], "X position before gap filling")
  )

ggsave(
  filename = paste0(
    "./results/marker_",
    markers_of_interest[sel_idx],
    "_x_position_before_gap_filling.png"),
  width = 10,
  height = 10,
  units = "cm",
  dpi = 300
)

# now we can apply our linear gap fill function to each column, by condition
selected_traj_data <- selected_traj_data %>% 
  group_by(condition, subject, marker) %>% 
  mutate_at(
    vars(x, y, z),
    ~ gap_fill_linear(.)
  )

# plot a single marker's x, y, and z after gap filling
selected_traj_data %>%
  dplyr::filter(marker == markers_of_interest[sel_idx]) %>%
  ggplot(aes(x = elapsed_time, y = x, color = subject)) +
  geom_line() +
  theme_minimal() +
  facet_wrap(c(~condition)) +
  labs(
    x = "Elapsed time",
    y = "Marker X position",
    title = paste("Marker", markers_of_interest[sel_idx], "X position after gap filling")
  )

ggsave(
  filename = paste0(
    "./results/marker_",
    markers_of_interest[sel_idx],
    "_x_position_after_gap_filling.png"),
  width = 10,
  height = 10,
  units = "cm",
  dpi = 300
)

```

```{r}
# Get a list of objects in the global environment
all_objects <- ls()

# Define a regular expression to match group identifiers followed by a number between 0 and 13
regex_pattern <- "^group([0-9]|1[0-3])_"

# Filter objects that match the pattern
group_objects <- grep(regex_pattern, all_objects, value = TRUE)

# Loop through each object and apply the operations
for (df_name in group_objects) {
  # Extract the current data frame
  df <- get(df_name)
  
  # Check if 'condition' and 'group' columns exist
  if (!all(c("condition", "group") %in% names(df))) {
    warning(paste("Data frame", df_name, "does not have 'condition' and/or 'group' columns. Skipping."))
    next
  }
  
  # Add factors for condition and group
  df$condition <- factor(df$condition)
  df$group <- factor(df$group)
  
  # Pivot the data
  df <- df %>% 
    pivot_longer(
      cols = contains("_x") | contains("_y") | contains("_z"),
      cols_vary = "slowest",
      names_to = "marker",
      values_to = "value"
    ) %>%
    mutate(
      subject = stri_replace_first_regex(marker, "^([AB])_.*", "$1"),
      axis = stri_extract_last_regex(marker, "[xyz]$"),
      marker = stri_replace_first_regex(marker, "^[AB]_([a-zA-Z_]+)_[xyz]$", "$1")
    ) %>%
    # Move axes to columns
    pivot_wider(
      names_from = axis,
      values_from = value
    )
  
  # Assign the modified data frame back to the original variable
  assign(df_name, df)
  
  # Print the data frame name
  cat("Data frame:", df_name, "\n")
  
  # Print the first few rows of the pivoted data frame
  print(head(df))
  
  cat("\n")
}
```
z

## ICA

We will do dimensionality reduction with ICA using the r package fastICA

<https://www.rdocumentation.org/packages/fastICA/versions/1.2-4/topics/fastICA> <https://cran.r-project.org/web/packages/iTensor/vignettes/iTensor-1.html>

In short ICA attempts to 'un-mix' the data by estimating an un-mixing matrix W where XW = S.

Under this generative model the measured 'signals' in X will tend to be \`more Gaussian' than the source components (in S) due to the Central Limit Theorem. Thus, in order to extract the independent components/sources we search for an un-mixing matrix W that maximizes the non-gaussianity of the sources.

In FastICA, non-gaussianity is measured using approximations to neg-entropy () which are more robust than kurtosis-based measures and fast to compute.

We need to do the following things in order to do ICA

1.  Convert dataframe to matrix
2.  Apply fastICA
3.  Plotting

## Am i supposed to do this on one marker or multiple markers?

## GroupICA

Peter's stuff: \## Start med at kigge på raw data (tag hver markers x-position) \## Eventuelt group ICA? -\> dynamic time warping \## ICA individually -\> Cross-correlation analysis \## Raw data

```{r Convert dataframe to matrix}
## dataframe with hand_right marker being converted to matrix
x <- data.matrix(selected_traj_data) 

## removing NA's as a temporary solution
x <- na.omit(x)
```

```{r apply ICA}
## We should try different functions
a <- fastICA(x, 3, alg.typ = "parallel", fun = "logcosh", alpha = 1,
             method = "R", row.norm = FALSE, maxit = 200,
             tol = 0.0001, verbose = TRUE)



## side note: neg-entropy is a way of measuring how much a distribution deviates from a Gaussian distribution. We want to maximize neg-entropy because it maximizes independence, which is the whole purpose of ICA.
```

```{r saving the independent components into a dataframe}
## Independent components yes no?!?!?!!
independent_components <- a$S # OH MAH GOD I UNDERSTAND NOTHITNREFD

independent_components <- as.data.frame(independent_components)
```

```{r plotting independent components}
par(mfrow = c(1, 3)) # Set up a 1x2 plotting grid for two components
## plotting the first independent component
independent_components[, 1] %>%
  plot()
## plotting the second independent component
independent_components[, 2] %>%
  plot()
## plotting the third independent component
independent_components[, 3] %>%
  plot()
```

```{r Plotting}
par(mfrow = c(1, 2))# Set up a 1x2 plotting grid for two components
plot(a$X)
plot(a$S)[,1] # WHAT IS THIS OH MAH GOD

## Plot the original data before applying ICA
for (i in 1:2) {
  plot(x[, i], type = "l", main = paste("Original Data Dimension", i), ylab = "Amplitude", xlab = "Time")
}
```

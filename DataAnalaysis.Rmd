---
title: "Data analysis"
author: "Nadia and Katharina"
output:
  html_document:
      toc: yes
      number_sections: no
      toc_float: yes
      theme: united
      highlight: espresso
      css: '../../varia/standard.css'
geometry: margin=1in
knit: (function(inputFile, encoding) {
  browseURL(
    rmarkdown::render(
      inputFile,
      encoding = encoding,
      output_dir = 'documents/assignments/solutions',
      output_file = "DataAnalysis.html"))})
---


```{r setuP}
## Setup chunk
knitr::opts_chunk$set(echo = TRUE, include = TRUE, message = FALSE, warning = FALSE)
```

Here i am just loading the packages and setting up our working directory. I am also specifying, which group we are looking at. 

```{r loading packages}
pacman::p_load(
  "XML",
  "tidyverse",
  "fs",
  "assertthat",
  "stringi",
  "dtw",
  "RTransferEntropy",
  "signal",
  "conflicted",
  "Rcpp",
  "future"
)

## Making sure we are in the right directory
wd <- getwd()
if (basename(wd) != "PerceptionActionExam") {
  setwd("./PerceptionActionExam")
}

# set the directory for the data
# note, path_home() will return the path to your home directory
# your home directory is the one that contains your documents, downloads, etc.
data_dir <- path_home() %>% 
  path("Documents", "GitHub", "PerceptionActionExam", "data", "tsvs")

# set your study group
group_number <- 1

# The available conditions and their start and end frame indices
# to use the whole file, just set the value for the condition to c(NA, NA)
conditions <- list(
  jointlead = c(NA, NA),
  followlead = c(NA, NA),
  leadfollow = c(NA, NA),
  custom = c(NA, NA)
)
```

In this section we are just defining functions, that will be used later on. The first function is process_qtm_tsv, which converts the QTM TSV file into a data frame. The second function is gap_fill_linear.

```{r defining functions}
process_qtm_tsv <- function(
    data_file,
    condition_regex = "group[0-9]+_([^_\\.]+).*", # a regular expression used to search for patterns
    null_value = "NA"
  ) {
  "This function processes a QTM TSV file and reads it into a dataframe.

  You will get both the trajectory data (dataframe) as well as metadata.

  Args:
    data_file (str): The path to the QTM TSV file.
    condition_regex (str): A regex to extract the condition from the file name.
    null_value (str): The value in the files that represents a missing measurement.

  Returns:
    A list with two elements:
      - data: The trajectory data as a dataframe.
      - metadata: A list with the metadata.
          The metadata contains the following elements:
            - condition: The condition of the data.
            - frequency: The frequency (Hz) of the data.
            - marker_count: The number of markers.
            - frame_count: The number of frames.
            - marker_names: The names of the markers.
  "

  message(paste("Processing", data_file))

  # get the condition
  cond <- stri_match_last_regex(data_file, condition_regex)[2]
  # make condition lowercase
  cond <- tolower(cond)
  message(paste("Condition:", cond))

  # read in the data
  dat <- readLines(data_file)

  # now get other relevant metadata
  # get frequency
  freq <- stri_match_first_regex(dat, "^FREQUENCY.*")
  freq <- freq[!is.na(freq)]

  # get marker count
  marker_count <- stri_extract_first_regex(dat, "^NO_OF_MARKERS.*")
  marker_count <- marker_count[!is.na(marker_count)]
  marker_count_value <- as.integer(stri_split_fixed(marker_count, "\t")[[1]][2])

  # get frame count
  frame_count <- stri_extract_first_regex(dat, "^NO_OF_FRAMES.*")
  frame_count <- frame_count[!is.na(frame_count)]
  frame_count_value <- as.integer(stri_split_fixed(frame_count, "\t")[[1]][2])

  # get marker names
  marker_names <- stri_extract_first_regex(dat, "^MARKER_NAMES.*")
  marker_names <- marker_names[!is.na(marker_names)]
  marker_names_values <- stri_split_fixed(
    marker_names,
    "\t"
  )[[1]][1:marker_count_value + 1]
  message("File information:")
  message(paste(freq, "Hz", "frequency"))
  message(paste(marker_count_value, "markers"))
  message(paste(frame_count_value, "frames"))

  # now just keep the tracking information
  dat <- stri_extract_first_regex(dat, "^[0-9]+\t.*")
  dat <- dat[!is.na(dat)]

  # now ensure the number of frames is correct
  # this is the number of lines in the data
  assertthat::assert_that(
    length(dat) == frame_count_value,
    msg = paste(
      "Number of frames is not correct, found:",
      length(dat),
      "expected:",
      frame_count_value)
  )

  # ensure the number of markers is correct
  # this is 3 columns per marker, plus index and time
  num_found_markers <- length(stri_split_fixed(dat[[1]], "\t")[[1]])
  assertthat::assert_that(
    num_found_markers == marker_count_value * 3 + 2,
    msg = paste(
      "Number of markers is not correct, found:",
      num_found_markers,
      "expected:",
      marker_count_value * 3 + 2)
  )

  message(paste("File has", length(dat), "frames"))
  message(paste("File has", marker_count_value, "markers"))

  message("Creating data frame...")

  col_names <- c(
    "index",
    "elapsed_time",
    paste0(
      rep(marker_names_values, each = 3),
      c("_x", "_y", "_z")
    )
  )


  # now we need to create a data frame
  
  # split each line by tab
  dat <- stri_split_fixed(dat, "\t", simplify = TRUE)
  # set the column names
  colnames(dat) <- col_names
  # and then convert to a data frame
  dat <- as_tibble(dat)
  # now we need to replace the null values with NA
  dat[dat == null_value] <- NA
  # and convert to numeric
  dat <- mutate_all(dat, as.numeric)

  metadata <- list(
    condition = cond,
    frequency = freq,
    marker_count = marker_count,
    frame_count = frame_count,
    marker_names = marker_names
  )

  # return the data and metadata
  return(list(data = dat, metadata = metadata))

}

gap_fill_linear <- function(x) {
  "This function does a linear gap fill for a vector.

  Only columns with at least 2 non-NA values will be gap filled.

  Args:
    x (vector): The vector to gap fill.

  Returns:
    The gap filled vector.
  "
  # get the indices of the NA values
  na_indices <- which(is.na(x))
  # get the indices of the non-NA values
  non_na_indices <- which(!is.na(x))

  if (length(na_indices) == 0) {
    # if there are no NA values, just return the vector
    return(x)
  }

  if (length(non_na_indices) < 2) {
    # if there are less than 2 non-NA values, we can't do a linear interpolation
    return(x)
  }
  # get the values of the non-NA indices
  non_na_values <- x[non_na_indices]
  # get the values of the NA indices
  na_values <- x[na_indices]
  # now we can do a linear interpolation
  na_values <- approx(
    x = non_na_indices,
    y = non_na_values,
    xout = na_indices,
    method = "linear"
  )$y
  # now we can replace the NA values with the interpolated values
  x[na_indices] <- na_values
  # and return the vector
  return(x)
}

```


And so, some more boring stuff...This is just getting the labels so we can make sure that the tracked markers match up with what we expected, really, this shouldn't go wrong, but if you don't check this kind of thing you'll end up scratching your head later wondering why everything broke.

```{r}
# load the labels from the XML file

# load the XML file
xmlfile <- xmlParse("PerAct23_LabelList.xml")

# get the labels, which are in the following format:
# <QTM_Label_List_Ver_1.00>
#     <Trajectories>
#         <Trajectory>
#             <Name>A_head_top</Name>
#             <Color R="0" G="147" B="0"/>
#         </Trajectory>
#     </Trajectories>
# </QTM_Label_List_Ver_1.00>

# get the trajectory names
traj_names <- xpathSApply(xmlfile, "//Trajectory/Name", xmlValue)

# get the trajectory colors
traj_colors <- xpathSApply(xmlfile, "//Trajectory/Color", xmlAttrs)

# convert the colors to hex
traj_colors <- rgb(
  as.numeric(traj_colors[1,]),
  as.numeric(traj_colors[2,]),
  as.numeric(traj_colors[3,]),
  alpha = 255,
  maxColorValue = 255
)


# combine the names and colors into a data frame
traj_labels <- data.frame(
  traj_names,
  traj_colors,
  stringsAsFactors = FALSE
)

rm(xmlfile, traj_names, traj_colors)
```

Finally loading in data hehehe (insert elmo meme with fire in the background)

```{r 'Load Trajectory Data'}
# load the trajectory data, we want all TSVs with the group number in the name

# get the files
traj_files <- fs::dir_ls(data_dir, regexp = paste0("group", group_number, "_.*\\.tsv$"))

# load the data
traj_data <- lapply(traj_files, process_qtm_tsv)

# now we need to combine the data into a single data frame

# first we need to add the condition and group to each data frame
traj_data <- lapply(traj_data, function(x) {
  x$data$condition <- x$metadata$condition
  x$data$group <- paste0("group", group_number)
  return(x)
})

# now we can combine the data
traj_data <- do.call(bind_rows, lapply(traj_data, `[[`, "data"))

# make the condition and group factors
traj_data$condition <- factor(traj_data$condition)
traj_data$group <- factor(traj_data$group)

# take a look at the data
head(traj_data)

# let's also make sure that all of the marker names are the same
# we can do this by getting the unique marker names
marker_names <- unique(traj_data %>% select(contains("_x")) %>% names() %>% stri_replace_last_regex("_x", ""))

# now we can check that all of the marker names are the same
assertthat::assert_that(
  all(marker_names == traj_labels$traj_names),
  msg = "Not all marker names are the same"
)

# let's make the data long format so we can easily group by subject or marker
traj_data <- traj_data %>% 
  pivot_longer(
    cols = contains("_x") | contains("_y") | contains("_z"),
    cols_vary = "slowest",
    names_to = "marker",
    values_to = "value"
  ) %>%
  mutate(
    subject = stri_replace_first_regex(marker, "^([AB])_.*", "$1"),
    axis = stri_extract_last_regex(marker, "[xyz]$"),
    marker = stri_replace_first_regex(marker, "^[AB]_([a-zA-Z_]+)_[xyz]$", "$1")
  )

# move axes to columns
traj_data <- traj_data %>% 
  pivot_wider(
    names_from = axis,
    values_from = value
  )

# Making sure that we have all of the different markers HEHEHEEH HI KAT
unique(traj_data$marker)

#traj_data$marker <- factor(traj_data$marker, levels = marker_names)


#In simple terms, this code is transforming data from a wide format, where each marker's x, y, and z coordinates are in separate columns, to a long format where all the coordinates are in a single column. It then adds more information about each observation (subject, axis, and marker) before pivoting it back to a wide format.

```
# Trim the trajectories

Here's where you cut the start and ends off of the trajectores, this is useful for example
when you know that there's some setup time or a delay from recording start to end, or if you just 
want to look at a specific section of the data.

If you set up the conditions correctly in the setup section, then you can just run this cell and it will
crop the data for you.

```{r 'Crop trajectory data'}

# We want to crop the data for each condition
# let's get all the recorded conditions
recorded_conditions <- unique(traj_data$condition)
for (cond in recorded_conditions) {
  # get the start and end frame for the condition
  start_frame <- conditions[[cond]][1]
  if (is.na(start_frame)) start_frame <- 1
  end_frame <- conditions[[cond]][2]
  if (is.na(end_frame)) end_frame <- max(traj_data[traj_data$condition == cond, "index"])
  # crop the data
  traj_data <- traj_data %>% 
    dplyr::filter(condition == cond & index >= start_frame & index <= end_frame | condition != cond)
}

# select min and max indices by condition
traj_data %>% 
  group_by(condition) %>% 
  summarise(
    min_index = min(index),
    max_index = max(index))

# report observations per condition
traj_data %>% 
  group_by(condition, subject, marker) %>% 
  summarise(
    n_obs = n()
  ) %>%
  print(n = 100)

```

```{r}
## Filtering out custom condition
traj_data <- traj_data %>% 
  dplyr::filter(condition %in% c("leadfollow", "followlead")) ## a bit confused why this works

## Checking to see if the filtering worked :)
traj_data %>%
  distinct(condition)
```
# Inspect the data

I've included some ways here of inspecting the data to see if there are any obvious problems.

## Check for large jumps in trajectory data

This is a simple check to see if there are any large jumps in the data, this can indicate that there are
some label errors (e.g. label `hand_left` became label `hand_right`), or that the data is just bad.

```{r 'Check for large jumps in trajectory data'}
# we want to check for large jumps in the data
# this indicates potential label errors

# we will do this by calculating the distance between each marker for each time point
# of course, by condition


# calculate the euclidean distance between each marker (using x, y, z)
# we will do this by condition, subject, marker and axis
marker_distances <- traj_data %>% 
  group_by(condition, subject, marker) %>%
  arrange(index) %>%
  mutate(
    diff_x = x - dplyr::lag(x, 1),
    diff_y = y - dplyr::lag(y, 1),
    diff_z = z - dplyr::lag(z, 1)
  )
  

# now we can calculate the euclidean distance per maker
marker_distances <- marker_distances %>% 
  mutate(
    euclidean_distance = sqrt(diff_x^2 + diff_y^2 + diff_z^2)
  )

# now we can plot the series for each marker, and see if anything stands out
marker_distances %>% 
  ggplot(aes(x = index, y = euclidean_distance)) +
  geom_line(aes(color = factor(marker)), linewidth=1.25) +
  theme_minimal() +
  facet_wrap(c(~condition, ~subject)) +
  labs(
    x = "Index",
    y = "Euclidean distance",
    title = "Euclidean distance from previous frame by marker"
  )

# save the plot
ggsave(
  filename = "./results/euclidean_distance_by_marker.png",
  width = 10,
  height = 10,
  units = "cm",
  dpi = 300
)

```
# Check for NAs

Specifically, this checks how much of a given trajectory is `NA` values and how long the longest sequence
of `NA` values is. This can be useful for deciding whether to discard a marker or not.

*Remember, you'll want to make sure that both subject A and B have at least one good quality matching marker.*

```{r 'Get information about NAs'}	

# get NAs counts
# by condition, marker, subject and axis
nas_cond_marker <- traj_data %>%
  group_by(condition, subject, marker) %>%
  summarise_at(
    vars(x, y, z),
    ~ sum(is.na(.))
  )

# plot to check if it is acceptable
nas_cond_marker %>% 
  ggplot(aes(x = marker, y = x, fill=marker, group=subject)) +
  geom_col(
    show.legend = FALSE
  ) +
  coord_flip() +
  theme_minimal() +
  facet_wrap(c(~subject, ~condition)) +
  labs(
    x = "Marker",
    y = "NA count",
    title = "NA count by marker"
  )

ggsave(
  filename = "./results/NA_count_by_marker.png",
  width = 10,
  height = 10,
  units = "cm",
  dpi = 300
)


# Now we can get the longest sequence of NAs for each marker
longest_na_seq <- traj_data %>% 
  group_by(condition, subject, marker) %>%
  summarise_at(
    vars(x, y, z),
    ~ max(rle(is.na(.))$lengths)
  )

# plot to check if it is acceptable
longest_na_seq %>% 
  ggplot(aes(x = marker, y = x, fill=marker, group=subject)) +
  geom_col(
    show.legend = FALSE
  ) +
  coord_flip() +
  theme_minimal() +
  facet_wrap(c(~subject, ~condition)) +
  labs(
    x = "Marker",
    y = "Longest NA sequence",
    title = "Longest NA sequence by marker"
  )

ggsave(
  filename = "./results/longest_na_sequence_by_marker.png",
  width = 10,
  height = 10,
  units = "cm",
  dpi = 300
)

```
## Note to self: This is probably, where will have to look at the different groups and check for NA's aka markers that haven't been labeled. Hopefully there isn't too many NA's and we can go straight to the analysis part. 



---
title: "Data analysis"
author: "Nadia and Katharina"
output:
  html_document:
      toc: yes
      number_sections: no
      toc_float: yes
      theme: united
      highlight: espresso
      css: '../../varia/standard.css'
geometry: margin=1in
knit: (function(inputFile, encoding) {
  browseURL(
    rmarkdown::render(
      inputFile,
      encoding = encoding,
      output_dir = "html.file",
      output_file = "DataAnalysis.html"))})
---

```{r setuP}
## Setup chunk
knitr::opts_chunk$set(echo = TRUE, include = TRUE, message = FALSE, warning = FALSE)
```

## Pre-processing

Here i am just loading the packages and setting up our working directory. I am also specifying, which group we are looking at.

```{r loading packages}
pacman::p_load(
  "XML",
  "tidyverse",
  "fs",
  "assertthat",
  "stringi",
  "dtw",
  "RTransferEntropy",
  "signal",
  "conflicted",
  "Rcpp",
  "future",
  "fastICA",
  "groupICA",
  "dtw",
  "dplyr",
  "plotly",
  "htmlwidgets"
)

## Making sure we are in the right directory
wd <- getwd()
if (basename(wd) != "PerceptionActionExam") {
  setwd("./PerceptionActionExam")
}

# set the directory for the data
# note, path_home() will return the path to your home directory
# your home directory is the one that contains your documents, downloads, etc.
# data_dir <- path_home() %>% 
#   path("Documents", "GitHub", "PerceptionActionExam", "data", "tsvs") ## Nadia's path

data_dir <- path_home() %>%
path("Desktop","UNI", "3.semester", "Perception & Action", "PerceptionActionExam", "data", "tsvs") ## Katharina's path


# The available conditions and their start and end frame indices
# to use the whole file, just set the value for the condition to c(NA, NA)
conditions <- list(
  jointlead = c(NA, NA),
  followlead = c(NA, NA),
  leadfollow = c(NA, NA),
  custom = c(NA, NA)
)

# Calling functions
source("Functions.R")
```

And so, some more boring stuff...This is just getting the labels so we can make sure that the tracked markers match up with what we expected, really, this shouldn't go wrong, but if you don't check this kind of thing you'll end up scratching your head later wondering why everything broke.

```{r}
# load the labels from the XML file

# load the XML file
xmlfile <- xmlParse("PerAct23_LabelList.xml")

# get the labels, which are in the following format:
# <QTM_Label_List_Ver_1.00>
#     <Trajectories>
#         <Trajectory>
#             <Name>A_head_top</Name>
#             <Color R="0" G="147" B="0"/>
#         </Trajectory>
#     </Trajectories>
# </QTM_Label_List_Ver_1.00>

# get the trajectory names
traj_names <- xpathSApply(xmlfile, "//Trajectory/Name", xmlValue)

# get the trajectory colors
traj_colors <- xpathSApply(xmlfile, "//Trajectory/Color", xmlAttrs)

# convert the colors to hex
traj_colors <- rgb(
  as.numeric(traj_colors[1,]),
  as.numeric(traj_colors[2,]),
  as.numeric(traj_colors[3,]),
  alpha = 255,
  maxColorValue = 255
)


# combine the names and colors into a data frame
traj_labels <- data.frame(
  traj_names,
  traj_colors,
  stringsAsFactors = FALSE
)

rm(xmlfile, traj_names, traj_colors)
```

Finally loading in data hehehe (insert elmo meme with fire in the background)

Aditionally, this code is transforming data from a wide format, where each marker's x, y, and z coordinates are in separate columns, to a long format where all the coordinates are in a single column. It then adds more information about each observation (subject, axis, and marker) before pivoting it back to a wide format.

```{r }
## the code lists files in the specified directory that have names ending with ".tsv" and stores the list of file paths in the variable traj_files.
traj_files <- fs::dir_ls(data_dir, regexp = "\\.tsv$")
```

## Loading the data in and giving meaningful names

```{r}
# Now we can actually load in the data. When we are loading in the data, we are also renaming out list to be the name of the individual groups and conditions 
traj_data_list <- list()

for (file_path in traj_files) {
  # Load the data from the file
  traj_data <- process_qtm_tsv(file_path)
  
  # Extract the group number and condition from the filename
  group_number <- sub(".*group([0-9]+).*\\.tsv", "\\1", basename(file_path))
  condition <- traj_data$metadata$condition
  
  # Create a unique identifier for the combination of group number and condition
  group_condition_identifier <- paste0("group", group_number, "_", condition)
  
  # Check if a dataframe with this identifier already exists in the list
  if (group_condition_identifier %in% names(traj_data_list)) {
    # If it exists, append the data to the existing dataframe
    traj_data_list[[group_condition_identifier]]$data <- rbind(traj_data_list[[group_condition_identifier]]$data, traj_data$data)
  } else {
    # If it doesn't exist, create a new dataframe and add it to the list
    traj_data_list[[group_condition_identifier]] <- traj_data
  }
}

# Now, traj_data_list contains individual lists for each unique combination of group number and condition
```

## Adding condition and group columns, so we can have nice individual dataframes later on

```{r}
traj_data_list <- lapply(traj_data_list, function(x) {
  # Add condition and group information to the data frame
  x$data$condition <- x$metadata$condition
  
  # Set x$data$group to be the list name
  x$data$group <- basename(file_path)
  
  return(x)
})
```

## So up until now the lists have been in one dataframe, so lets split them into multiple dataframes!

```{r}
library(dplyr)

# Assuming traj_data_list is a list of data frames with both 'data' and 'metadata'
for (i in seq_along(traj_data_list)) {
  x <- traj_data_list[[i]]
  
  # Check if 'data' and 'metadata' components exist in each list element
  if (!all(c("data", "metadata") %in% names(x))) {
    warning("List element does not have 'data' and/or 'metadata'. Skipping.")
    next
  }
  
  # Extract condition and group information from the file path
  file_path <- names(traj_data_list)[i]
  condition <- sub(".*group[0-9]+_([^_\\.]+).*", "\\1", file_path)
  group_number <- sub(".*group([0-9]+).*", "\\1", file_path)
  
  # Add condition and group information to the data frame
  x$data$condition <- condition
  x$data$group <- paste0("group", group_number)
  
  # Create a new data frame with the processed data and name it
  new_df_name <- paste0("group", group_number, "_", condition)
  assign(new_df_name, x$data)
}

```

## Turning condition and group into factors and ensuring all marker names are not the same

```{r}
# Get a list of objects in the global environment
all_objects <- ls()

 # regex
regex_pattern <- "^group([0-9]|1[0-3])_"

# Filter objects that match the pattern
group_objects <- grep(regex_pattern, all_objects, value = TRUE)

# Loop through each object and apply the operations
for (df_name in group_objects) {
  # Extract the current data frame
  df <- get(df_name)
  
  # Check if 'condition' and 'group' columns exist
  if (!all(c("condition", "group") %in% names(df))) {
    warning(paste("Data frame", df_name, "does not have 'condition' and/or 'group' columns. Skipping."))
    next
  }
  
  # Add factors for condition and group
  df$condition <- factor(df$condition)
  df$group <- factor(df$group)
  
  # Print the data frame name
  cat("Data frame:", df_name, "\n")
  
  # Print the first few rows of the data frame
  print(head(df))
  
  # Ensure all marker names are the same
  marker_names <- unique(df %>% select(contains("_x")) %>% names() %>% stri_replace_last_regex("_x", ""))
  
  assertthat::assert_that(
    all(marker_names == traj_labels$traj_names),
    msg = paste("Not all marker names are the same in Data frame", df_name)
  )
  
  cat("\n")
}
```

## Going from wide format to long format

```{r}
# Get a list of objects in the global environment
all_objects <- ls()

# Define a regular expression to match group identifiers followed by a number between 0 and 13
regex_pattern <- "^group([0-9]|1[0-3])_"

# Filter objects that match the pattern
group_objects <- grep(regex_pattern, all_objects, value = TRUE)

# Loop through each object and apply the operations
for (df_name in group_objects) {
  # Extract the current data frame
  df <- get(df_name)
  
  # Check if 'condition' and 'group' columns exist
  if (!all(c("condition", "group") %in% names(df))) {
    warning(paste("Data frame", df_name, "does not have 'condition' and/or 'group' columns. Skipping."))
    next
  }
  
  # Pivot the data
  df <- df %>% 
    pivot_longer(
      cols = contains("_x") | contains("_y") | contains("_z"),
      cols_vary = "slowest",
      names_to = "marker",
      values_to = "value"
    ) %>%
    mutate(
      subject = stri_replace_first_regex(marker, "^([AB])_.*", "$1"),
      axis = stri_extract_last_regex(marker, "[xyz]$"),
      marker = stri_replace_first_regex(marker, "^[AB]_([a-zA-Z_]+)_[xyz]$", "$1")
    ) %>%
    # Move axes to columns
    pivot_wider(
      names_from = axis,
      values_from = value
    )
  
  # Assign the modified data frame back to the original variable
  assign(df_name, df)
  
  # Print the data frame name
  cat("Data frame:", df_name, "\n")
  
  # Print the first few rows of the pivoted data frame
  print(head(df))
  
  cat("\n")
}
```

## Trimming to 30 sec

Before proceeding we must trim the trajectories to accurately match the window of data collection - meaning, we must identify the 30 second window from which the t-pose starts.

Our original dataframes have a frame every 0,003rd second, so in order to save computational power, we simplify the dataframe for visualisation. In this case we will have points every half second.

```{r}
# List objects in your environment that match the pattern
matching_objects <- ls(pattern = "^group.*_(jointlead|leadfollow)$")

# Create df_list by loading the matching dataframes
df_list <- lapply(matching_objects, get)
  
# Create an empty list to store the simplified dataframes
simplified_df_list <- list()

# Iterate through the list of dataframes
for (current_df in df_list) {
  # Apply the transformation and store the simplified dataframe in a new list
  simplified_df <- current_df %>%
    group_by(subject, marker) %>%
    slice(seq(1, n(), by = 151)) %>%
    ungroup()
  
  # Add the simplified dataframe to the new list
  simplified_df_list <- c(simplified_df_list, list(simplified_df))
}

```

Then we make 3d plots with included timeframe to identify the t-poses and thereby where our 30 second window starts.

```{r}
# Create an empty list to store the plots
plot_list <- list()

# Iterate through the simplified dataframes
for (i in seq_along(simplified_df_list)) {
  df_name <- names(simplified_df_list)[i]
  df <- simplified_df_list[[i]]
  
  # Create the base plot
  fig <- plot_ly(df, 
                 x = ~x, 
                 y = ~y, 
                 z = ~z, 
                 type = "scatter3d", 
                 mode = "markers", 
                 size = 2,
                 frame = ~elapsed_time,
                 marker = list(size = 4), ## Adjusting the marker size
                 color = ~subject)
  
  fig <- fig %>% plotly::layout(
    scene = list(
      xaxis = list(title = "X-axis", range = c(-800, 800)), 
      yaxis = list(title = "Y-axis", range = c(-800, 800)),
      zaxis = list(title = "Z-axis", range = c(0, 1800)),
      aspectmode = "manual",
      aspectratio = list(x = 1, y = 1, z = 1)
    ),
    xaxis = list(title = "X-axis"), 
    yaxis = list(title = "Y-axis"),
    zaxis = list(title = "Z-axis"))
  
  fig <- fig %>% ## adding and changing text
    plotly::layout(title = list(text = df_name, y = 0.9), 
                   font=list(size=15, family = "Times new roman"),
                   legend = list(title = list(text = "markers")))
  
  plot_list[[i]] <- fig
}

# Now plot_list contains all the plots for each simplified dataframe

# Save each plot in plot_list as an HTML file
for (i in seq_along(plot_list)) {
  plot <- plot_list[[i]]
  filename <- paste0("plot_", i, ".html")
  saveWidget(plot, file = filename)
}
```

```{r}
plot_list
```

Now, we manually identify the values of elapsed_time that correspond to the beginning for each group and condition.

```{r}
start_time_df <- data.frame(
  group_and_condition = c("group0_jointlead",
                          "group0_leadfollow",
                          "group1_jointlead",
                          "group1_leadfollow",
                          "group12_jointlead",
                          "group12_leadfollow",
                          "group13_jointlead",
                          "group13_leadfollow",
                          "group2_jointlead",
                          "group2_leadfollow",
                          "group3_jointlead",
                          "group3_leadfollow",
                          "group4_leadfollow",
                          "group6_jointlead",
                          "group6_leadfollow",
                          "group8_leadfollow"),
  elapsed_time_at_start = as.numeric(c("17",
                            "35",
                            "12",
                            "50",
                            "33",
                            "28",
                            "37",
                            "94",
                            "18",
                            "31",
                            "12",
                            "42",
                            "37",
                            "14",
                            "29",
                            "52")
                            )
)
```

Now we will iterate through all the group dataframes and pick the elapsed_time value associated.

```{r}
# Store your dataframes in a list (same as before)
dataframes_list <- list(
  group0_jointlead,
  group0_leadfollow,
  group1_jointlead,
  group1_leadfollow,
  group12_jointlead,
  group12_leadfollow,
  group13_jointlead,
  group13_leadfollow,
  group2_jointlead,
  group2_leadfollow,
  group3_jointlead,
  group3_leadfollow,
  group4_leadfollow,
  group6_jointlead,
  group6_leadfollow,
  group8_leadfollow
)

# Create an empty list to store the subset dataframes
subset_dataframes <- list()

# Iterate through rows of start_time_df and extract subsets
for (i in 1:nrow(start_time_df)) {
  df_name <- start_time_df$group_and_condition[i]
  start_time <- start_time_df$elapsed_time_at_start[i]
  
  # Find the corresponding dataframe, if it exists
  if (exists(df_name)) {
    df <- get(df_name)
    
    # Arrange the dataframe by elapsed_time
    df <- df %>%
      arrange(elapsed_time)
    
    # Extract the subset based on the starting value
    starting_index <- which(df$elapsed_time == start_time)[1]
    ending_index <- which(df$elapsed_time == start_time + 30)[1]
    
    if (!is.na(starting_index) && !is.na(ending_index)) {
      subset_df <- df[starting_index:ending_index, ]
      subset_dataframes[[i]] <- subset_df
      
      # Replace the original dataframe in the global environment
      assign(df_name, subset_df, envir = .GlobalEnv)
    } else {
      subset_dataframes[[i]] <- NULL  # Handle cases where the indices are not found
    }
  } else {
    subset_dataframes[[i]] <- NULL  # Handle cases where the dataframe does not exist
  }
}

# Now, the original dataframes have been replaced with the new ones in the global environment

```

## NA checking

For the most accurate analysis we want to include the following markers: Head, both hands and elbows, and chest. Before proceeding we check for NA's to verify none of these markers have too many NAs.

```{r}
# Get a list of objects in the workspace
objects <- ls()

# Filter objects that start with "group" followed by a number and underscore
group_dataframes <- grep("^group\\d+_", objects, value = TRUE)

# Iterate over the matching dataframes and apply the operation
for (df_name in group_dataframes) {
  df <- get(df_name)  # Get the dataframe
  
  # Identify columns with NAs
  na_columns <- colnames(df)[colSums(is.na(df)) > 0]
  
  # Select "marker" column and columns with NAs
  columns_to_summarize <- c("marker", na_columns)
  
  result <- df %>%
    select(all_of(columns_to_summarize)) %>%
    group_by(marker) %>%
    summarise(across(everything(), ~ sum(is.na(.)))) %>%
    arrange(across("x"))
  
  print(result)
}
```

## NA checking - we noticed that head_top didn't have a lot of NA's, so we checked whether or not it was the extra marker for A

```{r checking to see which markers B have}
  group0_jointlead %>%
  dplyr::filter(subject == "B") %>%
  distinct(marker)

## Subject B has no head_top heheheheheee
```

## Visualising the NAs

```{r}
# Get a list of objects in the workspace
objects <- ls()

# Process Joint Lead Dataframes
joint_lead_dataframes <- grep("_jointlead$", objects, value = TRUE)
joint_lead_list <- lapply(joint_lead_dataframes, get)
joint_lead_combined <- bind_rows(joint_lead_list, .id = "group") %>%
  mutate(type = "joint_lead")

# Process Lead Follow Dataframes
lead_follow_dataframes <- grep("_leadfollow$", objects, value = TRUE)
lead_follow_list <- lapply(lead_follow_dataframes, get)
lead_follow_combined <- bind_rows(lead_follow_list, .id = "group") %>%
  mutate(type = "lead_follow")

# Combine both datasets
combined_df <- bind_rows(joint_lead_combined, lead_follow_combined)

# Identifying columns with NAs and processing
na_columns <- colnames(combined_df)[colSums(is.na(combined_df)) > 0]
columns_to_summarize <- c("marker", na_columns, "group", "type")

# Summarize the number of NAs for each marker
result <- combined_df %>%
  select(all_of(columns_to_summarize)) %>%
  group_by(group, marker, type) %>%
  summarise(across(everything(), ~ sum(is.na(.))), .groups = "drop") %>%
  arrange(marker, type)


# Plotting with facet wrap
p <- ggplot(result, aes(x = marker, y = x, fill = marker)) +
  geom_bar(stat = "identity", position = "dodge", show.legend = FALSE) +
  labs(title = "NA's in Combined Dataframes", x = "Marker", y = "Number of NA") +
  facet_wrap(~ type) +
  coord_flip()

# Print the combined plot
print(p)
```

```{r}
# Now we can get the longest sequence of NAs for each marker
longest_na_seq <- combined_df %>% 
  group_by(condition, subject, marker) %>%
  summarise_at(
    vars(x, y, z),
    ~ max(rle(is.na(.))$lengths)
  )

# plot to check if it is acceptable
longest_na_seq %>% 
  ggplot(aes(x = marker, y = x, fill=marker, group=subject)) +
  geom_col(
    show.legend = FALSE
  ) +
  coord_flip() +
  facet_wrap(c(~subject, ~condition)) +
  labs(
    x = "Marker",
    y = "Longest NA sequence",
    title = "Longest NA sequence by marker"
  )
```

Unfortunately, the elbow markers have a lot of NA's. According to our plots, the head markers are consistently low in NA's, while the distribution of NA's for hands and chest is not consistent throughout the groups, we continue with checking the euclydian distance to further verify the validity of choosing said markers. However, the head_top is only present for participant A, and therefore we must choose either head_left or head_right. Since head_right has fewer NA's and the longest sequence is also smaller, we proceed with head_right

### Euclidean distance

```{r Euclidean distance plots for each marker}
for (df_name in group_objects) {
  # Extract the current data frame
  df <- get(df_name)

  # Calculate the euclidean distance between each marker (using x, y, z)
  # We will do this by subject, marker, and axis
  marker_distances <- df %>% 
    group_by(subject, marker) %>%
    arrange(index) %>%
    mutate(
      diff_x = x - dplyr::lag(x, 1),
      diff_y = y - dplyr::lag(y, 1),
      diff_z = z - dplyr::lag(z, 1)
    ) %>%
    mutate(
      euclidean_distance = sqrt(diff_x^2 + diff_y^2 + diff_z^2)
    )

  # Plot the series for each marker, and see if anything stands out
  plot <- marker_distances %>% 
    ggplot(aes(x = index, y = euclidean_distance)) +
    geom_line(aes(color = factor(marker)), linewidth = 1.25) +
    theme_minimal() +
    facet_wrap(~condition + subject) +
    labs(
      x = "Index",
      y = "Euclidean distance",
      title = "Euclidean distance from the previous frame by marker",
      subtitle = paste( df$group[1], "Condition:", df$condition[1])
    )
  
  # Print the plot
  print(plot)
}
```

```{r euclidean_distance_selected_markers}
##ONLY SPECIFIC LABELS##
for (df_name in group_objects) {
  # Extract the current data frame
  df <- get(df_name)

  # Calculate the euclidean distance between each marker (using x, y, z)
  # We will do this by subject, marker, and axis
  marker_distances <- df %>% 
    group_by(subject, marker) %>%
    arrange(index) %>%
    mutate(
      diff_x = x - dplyr::lag(x, 1),
      diff_y = y - dplyr::lag(y, 1),
      diff_z = z - dplyr::lag(z, 1)
    ) %>%
    mutate(
      euclidean_distance = sqrt(diff_x^2 + diff_y^2 + diff_z^2)
    )%>%
    # Filter only the specified markers
    dplyr::filter(marker %in% c("head_right", "hand_right", "hand_left", "chest"))


  # Plot the series for each marker, and see if anything stands out
  plot <- marker_distances %>% 
    ggplot(aes(x = index, y = euclidean_distance)) +
    geom_line(aes(color = factor(marker)), linewidth = 1.25) +
    theme_minimal() +
    facet_wrap(~condition + subject) +
    labs(
      x = "Index",
      y = "Euclidean distance",
      title = "Euclidean distance from the previous frame by marker",
      subtitle = paste( df$group[1], "Condition:", df$condition[1])
    )
  
  # Print the plot
  print(plot)
}
```

### Inspecting the raw data by plotting the x-coordinates

(inspecting to further validate the selection of markers -\> the markers chosen account for most of movement)

```{r for loop that plots x-coordinates for all markers in all groups}
## Making a for loop that plots x-coordinates for all markers in all groups
for (df_name in group_objects) {
  # Extract the current data frame
  df <- get(df_name)
  
  # Create ggplot
  plot <- ggplot(df, aes(x = x, y = marker)) +
    geom_point() +
    ggtitle(paste("Group:", df$group[1], "Condition:", df$condition[1]))
  
  # Print the plot
  print(plot)
}
```

## Choosing markers

Before filling gaps, we specify the markers we wish to choose. As specified before, we choose chest, hands and head.

```{r}
# get the markers of interest
markers_of_interest <- c(
  "hand_right",
  "head_right",
  "hand_left",
  "chest"
)

# now we can select the markers of interest
selected_traj_data <- combined_df %>% 
  dplyr::filter(marker %in% markers_of_interest)
```

```{r}
#NA
summarise_all(selected_traj_data, ~ sum(is.na(.)))
selected_traj_data %>%
  group_by(marker) %>%
  summarise(na_count = sum(is.na(x)))

#NON NA
selected_traj_data %>%
  group_by(marker) %>%
  summarise(non_na_count = sum(!is.na(x)))

```

Our data is roughly 1/4 parts NA's; we proceed with linear gap filling to try and minimize this number.

## Gap-filling

```{r}
# Assuming markers_of_interest is defined and has at least 4 elements
for(n in 1:9){
  for (sel_idx in 1:4) {
  selected_traj_data <- combined_df %>% 
  dplyr::filter(marker %in% markers_of_interest)
  
  # Plot a single marker's x, y, and z values before gap filling
  plot_before <- selected_traj_data %>%
    dplyr::filter(group == n) %>% 
    dplyr::filter(marker == markers_of_interest[sel_idx]) %>%
    ggplot(aes(x = elapsed_time, y = x, color=subject)) +
    geom_line() +
    facet_wrap(c(~condition)) +
    labs(
      x = "Elapsed time",
      y = "Marker X position",
      title = paste("Marker", markers_of_interest[sel_idx], "X position before gap filling", "group", n)
    )
  
  print(plot_before)

  ggsave(
    plot_before,
    filename = paste0(
      "./results/marker_",
      markers_of_interest[sel_idx],
      "group",
      n,
      "_x_position_before_gap_filling.png"),
    width = 10,
    height = 10,
    units = "cm",
    dpi = 300
  )

  # Apply the linear gap fill function to each column, by condition
  selected_traj_data <- selected_traj_data %>% 
    group_by(condition, subject, marker) %>% 
    mutate_at(
      vars(x, y, z),
      ~ gap_fill_linear(.)
    )

  # Plot a single marker's x, y, and z values after gap filling
  plot_after <- selected_traj_data %>%
    dplyr::filter(group == n) %>% 
    dplyr::filter(marker == markers_of_interest[sel_idx]) %>%
    ggplot(aes(x = elapsed_time, y = x, color = subject)) +
    geom_line() +
    facet_wrap(c(~condition)) +
    labs(
      x = "Elapsed time",
      y = "Marker X position",
      title = paste("Marker", markers_of_interest[sel_idx], "X position after gap filling", "group", n)
    )
  
  print(plot_after)

  ggsave(
    plot_after,
    filename = paste0(
      "./results/marker_",
      markers_of_interest[sel_idx],
      "group",
      n,
      "_x_position_after_gap_filling.png"),
    width = 10,
    height = 10,
    units = "cm",
    dpi = 300
  )
  }
}

```

```{r}

```

\-\-\-\-\-\--

#### ICA

```{r Convert dataframe to matrix}
## converting to matrix
x <- data.matrix(group8_leadfollow)

## removing NA's as a temporary solution
x <- na.omit(x)
```

```{r}
## filtering time
group8_leadfollow_sub <- group8_leadfollow %>%
  dplyr::filter(elapsed_time <= 5 )
  
## splitting dataframes by subject
df_A <- group8_leadfollow_sub %>% dplyr::filter(subject == "A")
df_B <- group8_leadfollow_sub %>% dplyr::filter(subject == "B")

## making them into matrices
df_A_x <- data.matrix(df_A) 
df_b_x <- data.matrix(df_B) 

## removing NA's 
df_A_x <- na.omit(df_A_x) 
df_b_x <- na.omit(df_b_x) 
```

```{r apply ICA}
## for both subject in one dataframe
a <- fastICA(x, 5, alg.typ = "parallel", fun = "logcosh", alpha = 1,
             method = "R", row.norm = FALSE, maxit = 200,
             tol = 0.0001, verbose = TRUE)

## for subject A
A <- fastICA(df_A_x, 2, alg.typ = "parallel", fun = "logcosh", alpha = 1,
             method = "R", row.norm = FALSE, maxit = 200,
             tol = 0.0001, verbose = TRUE)

## for subject B
B <- fastICA(df_b_x, 2, alg.typ = "parallel", fun = "logcosh", alpha = 1,
             method = "R", row.norm = FALSE, maxit = 200,
             tol = 0.0001, verbose = TRUE)

## Extracting the individual components
A1 <- A$S
B1 <- B$S

## side note: neg-entropy is a way of measuring how much a distribution deviates from a Gaussian distribution. We want to maximize neg-entropy because it maximizes independence, which is the whole purpose of ICA.
```

```{r dynamic time warping}
## limit reached
dtw_result <- dtw::dtw(A1, B1, keep = TRUE)

# Access the DTW distance
dtw_distance <- dtw_result$distance

# Print the DTW distance
print(paste("DTW Distance:", dtw_distance))

```

```{r}
window_size_samples <- 50


  result <- dtw(
          x = A1,
          y = B1,
          window.type = "none",
          window.size = window_size_samples,
          keep = TRUE
        )
```

```{r}
dtw(
  x = A1,
  y = B1,
  dist.method = "Euclidean",
  step.pattern = symmetric2,
  window.type = "none",
  keep.internals = FALSE,
  distance.only = FALSE,
  open.end = FALSE,
  open.begin = FALSE,
)
```

```{r saving the independent components into a dataframe}
## Independent components yes no?!?!?!!
independent_components <- a$S # OH MAH GOD I UNDERSTAND NOTHITNREFD

independent_components <- as.data.frame(independent_components)
```

```{r plotting independent components}
par(mfrow = c(1, 5)) # Set up a 1x2 plotting grid for two components
## plotting the first independent component
independent_components[, 1] %>%
  plot()
## plotting the second independent component
independent_components[, 2] %>%
  plot()
## plotting the third independent component
independent_components[, 3] %>%
  plot()
## plotting the fourth independent component
independent_components[, 4] %>%
  plot()
## plotting the fifthindependent component
independent_components[, 5] %>%
  plot()



i <- independent_components[, 1]

ii <- independent_components[, 2]
```

#### DTW

```{r}
dtw(
  x = A1,
  y = B1,
  step.pattern = symmetric2,
  window.type = "none",
  keep.internals = FALSE,
  distance.only = FALSE,
  open.end = FALSE,
  open.begin = FALSE,
)


 result <- dtw(
          x = A1,
          y = B1,
          window.type = "sakoechiba",
          window.size = window_size_samples,
          keep = TRUE
        )



# Assuming 'independent_components' is your time series data
data("aami3a")
ref <- window(aami3a,start=0,end=2)
test <- window(aami3a,start=2.7,end=5)
plot(dtw(test,ref,k=TRUE),type="two",off=1,match.lty=2,match.indices=20)


```

```{r}
  result <- dtw(
          x = cond_data[cond_data$subject == "A", axis],
          y = cond_data[cond_data$subject == "B", axis],
          window.type = "sakoechiba",
          window.size = window_size_samples,
          keep = TRUE
        )
      },
      error = function(e) {
        warning(paste(
          "Error doing DTW, skipping...maybe try standardizing?",
          "Condition:",
          cond,
          "Marker:",
          sel_marker,
          "Axis:",
          axis,
          "Length of A:",
          length(cond_data[cond_data$subject == "A", axis]),
          "Length of B:",
          length(cond_data[cond_data$subject == "B", axis]),
          "Error:",
          e
          )
        )
        result <- NULL
      }
    )
    if (is.null(result)) {
      message("Skipping...check warning messages at end of output")
      next
    }
    results[[length(results) + 1]] <- list(
      condition = cond,
      marker = sel_marker,
      axis = axis,
      normalizedDistance = result$normalizedDistance,
      distance = result$distance
    )
      
```

---
title: "Data analysis"
author: "Nadia and Katharina"
output:
  html_document:
      toc: yes
      number_sections: no
      toc_float: yes
      theme: united
      highlight: espresso
      css: '../../varia/standard.css'
geometry: margin=1in
knit: (function(inputFile, encoding) {
  browseURL(
    rmarkdown::render(
      inputFile,
      encoding = encoding,
      output_dir = "html.file",
      output_file = "DataAnalysis.html"))})
---

```{r setup}
## Setup chunk
knitr::opts_chunk$set(echo = TRUE, include = TRUE, message = FALSE, warning = FALSE)


pacman::p_load(
  "XML",
  "tidyverse",
  "fs",
  "assertthat",
  "stringi",
  "dtw",
  "RTransferEntropy",
  "signal",
  "conflicted",
  "Rcpp",
  "future",
  "fastICA",
  "groupICA",
  "dtw",
  "dplyr",
  "plotly",
  "htmlwidgets",
  "hrbrthemes",
  "zoo"
)
conflicts_prefer(dplyr::filter)
## Making sure we are in the right directory
wd <- getwd()
if (basename(wd) != "PerceptionActionExam") {
  setwd("./PerceptionActionExam")
}

                              ##NADIA PATH##
# data_dir <- path_home() %>% 
#   path("Documents", "GitHub", "PerceptionActionExam", "data", "tsvs") ## Nadia's path

                              #KATHARINA PATH##
data_dir <- path_home() %>%
path("Desktop","UNI", "3.semester", "Perception & Action", "PerceptionActionExam", "data", "tsvs") ## Katharina's path


theme_set(theme_minimal())
```

## Pre-processing

Loading functions made by Luke for later processing + making sure we are getting the conditions we want.

```{r loading packages}
# The available conditions and their start and end frame indices
# to use the whole file, just set the value for the condition to c(NA, NA)
conditions <- list(
  jointlead = c(NA, NA),
  leadfollow = c(NA, NA)
)

# Calling functions
source("Functions.R")
```

And so, some more boring stuff...This is just getting the labels so we can make sure that the tracked markers match up with what we expected, really, this shouldn't go wrong, but if you don't check this kind of thing you'll end up scratching your head later wondering why everything broke.

```{r}
# load the labels from the XML file

# load the XML file
xmlfile <- xmlParse("PerAct23_LabelList.xml")

# get the labels, which are in the following format:
# <QTM_Label_List_Ver_1.00>
#     <Trajectories>
#         <Trajectory>
#             <Name>A_head_top</Name>
#             <Color R="0" G="147" B="0"/>
#         </Trajectory>
#     </Trajectories>
# </QTM_Label_List_Ver_1.00>

# get the trajectory names
traj_names <- xpathSApply(xmlfile, "//Trajectory/Name", xmlValue)

# get the trajectory colors
traj_colors <- xpathSApply(xmlfile, "//Trajectory/Color", xmlAttrs)

# convert the colors to hex
traj_colors <- rgb(
  as.numeric(traj_colors[1,]),
  as.numeric(traj_colors[2,]),
  as.numeric(traj_colors[3,]),
  alpha = 255,
  maxColorValue = 255
)


# combine the names and colors into a data frame
traj_labels <- data.frame(
  traj_names,
  traj_colors,
  stringsAsFactors = FALSE
)

rm(xmlfile, traj_names, traj_colors) #cleaning up
```

Finally loading in data hehehe (insert elmo meme with fire in the background)

Aditionally, this code is transforming data from a wide format, where each marker's x, y, and z coordinates are in separate columns, to a long format where all the coordinates are in a single column. It then adds more information about each observation (subject, axis, and marker) before pivoting it back to a wide format.

```{r }
## the code lists files in the specified directory that have names ending with ".tsv" and stores the list of file paths in the variable traj_files.
traj_files <- fs::dir_ls(data_dir, regexp = "\\.tsv$")
```

## Loading the data in and giving meaningful names

We make a list that contains all the individual dataframes. This list will be called on and iterated through throughout the next steps. (was called traj_data_list in lukes script. Here it is list_of_dataframes)

```{r}
# Now we can actually load in the data. When we are loading in the data, we are also renaming our list to be the name of the individual groups and conditions 
list_of_dataframes <- list()

for (file_path in traj_files) {
  # Load the data from the file
  traj_data <- process_qtm_tsv(file_path)
  
  # Extract the group number and condition from the filename
  group_number <- sub(".*group([0-9]+).*\\.tsv", "\\1", basename(file_path))
  condition <- traj_data$metadata$condition
  
  # Create a unique identifier for the combination of group number and condition
  group_condition_identifier <- paste0("group", group_number, "_", condition)
  
  # Check if a dataframe with this identifier already exists in the list
  if (group_condition_identifier %in% names(list_of_dataframes)) {
    # If it exists, append the data to the existing dataframe
    list_of_dataframes[[group_condition_identifier]]$data <- rbind(list_of_dataframes[[group_condition_identifier]]$data, traj_data$data)
  } else {
    # If it doesn't exist, create a new dataframe and add it to the list
    list_of_dataframes[[group_condition_identifier]] <- traj_data
  }
}

# Now, list_of_dataframes contains individual lists for each unique combination of group number and condition

rm(group_condition_identifier,group_number)
```

## Adding condition and group columns, so we can have nice individual dataframes later on

```{r}
list_of_dataframes <- lapply(list_of_dataframes, function(x) {
  # Add condition and group information to the data frame
  x$data$condition <- x$metadata$condition
  
  # Set x$data$group to be the list name
  x$data$group <- basename(file_path)
  
  return(x)
})
```

## Cleaning up the list

Making sure the list only contains the data from each group, and not the metadata.

```{r}
# Assuming list_of_dataframes is a list of data frames with both 'data' and 'metadata'
for (i in seq_along(list_of_dataframes)) {
  x <- list_of_dataframes[[i]]
  
  # Check if 'data' and 'metadata' components exist in each list element
  if (!all(c("data", "metadata") %in% names(x))) {
    warning("List element does not have 'data' and/or 'metadata'. Skipping.")
    next
  }
  
  # Extract condition and group information from the file path
  file_path <- names(list_of_dataframes)[i]
  condition <- sub(".*group[0-9]+_([^_\\.]+).*", "\\1", file_path)
  group_number <- sub(".*group([0-9]+).*", "\\1", file_path)
  
  # Add condition and group information to the data frame
  x$data$condition <- condition
  x$data$group <- paste0("group", group_number)
  
  # Overwrite the original list element with the processed data
  list_of_dataframes[[i]] <- x$data
}

# 'list_of_dataframes' now contains all the processed data frames


rm(x, condition, group_number, i) #Cleaning up
```

## Turning condition and group into factors and ensuring all marker names are not the same

The columns "group" and "condition" shall be looked at as factors, and we are also performing quality control to make sure no markers have weird unique names.

```{r}
library(dplyr)
library(stringi)  # For stri_replace_last_regex
library(assertthat)  # For assert_that

# Loop through each index of the list
for (i in seq_along(list_of_dataframes)) {
  # Extract the current data frame directly from the list
  df <- list_of_dataframes[[i]]
  
  # Check if 'condition' and 'group' columns exist
  if (!all(c("condition", "group") %in% names(df))) {
    warning(paste("Data frame at index", i, "does not have 'condition' and/or 'group' columns. Skipping."))
    next
  }
  
  # Add factors for condition and group
  df$condition <- factor(df$condition)
  df$group <- factor(df$group)
  
  # Print the data frame index
  cat("Data frame at index:", i, "\n")
  
  # Print the first few rows of the data frame
  print(head(df))
  
  # Ensure all marker names are the same
  marker_names <- unique(df %>% select(contains("_x")) %>% names() %>% stri_replace_last_regex("_x", ""))
  
  assert_that(
    all(marker_names == traj_labels$traj_names),
    msg = paste("Not all marker names are the same in Data frame at index", i)
  )
  
  # Update the original data frame in the list
  list_of_dataframes[[i]] <- df
  
  cat("\n")
}
rm(df)
```

## Going from wide format to long format

Final step before we can work on the dataframes. Currently, the

```{r}
library(dplyr)
library(tidyr)
library(stringi)  # For string manipulation

# Loop through each index of the list
for (i in seq_along(list_of_dataframes)) {
  # Extract the current data frame directly from the list
  df <- list_of_dataframes[[i]]
  
  # Check if 'condition' and 'group' columns exist
  if (!all(c("condition", "group") %in% names(df))) {
    warning(paste("Data frame at index", i, "does not have 'condition' and/or 'group' columns. Skipping."))
    next
  }
  
  # Pivot the data
  df <- df %>% 
    pivot_longer(
      cols = contains("_x") | contains("_y") | contains("_z"),
      names_to = "marker",
      values_to = "value"
    ) %>%
    mutate(
      subject = stri_replace_first_regex(marker, "^([AB])_.*", "$1"),
      axis = stri_extract_last_regex(marker, "[xyz]$"),
      marker = stri_replace_first_regex(marker, "^[AB]_([a-zA-Z_]+)_[xyz]$", "$1")
    ) %>%
    # Move axes to columns
    pivot_wider(
      names_from = axis,
      values_from = value
    )
  
  # Update the original data frame in the list
  list_of_dataframes[[i]] <- df
  
  # Print the data frame index
  cat("Data frame at index:", i, "\n")
  
  # Print the first few rows of the pivoted data frame
  print(head(df))
  
  cat("\n")
}
# Now 'list_of_dataframes' contains all the modified data frames
rm(df, i, marker_names)
```

## Sorting by time

```{r}
# Loop through each dataframe in the list and arrange by 'elapsed_time'
list_of_dataframes <- lapply(list_of_dataframes, function(df) {
  df %>% arrange(elapsed_time)
})
```

## Saving CSVs

Now we have succesfully converted the files from Qualysis into dataframes that we can work on throughout the project, we will save each dataframe to a seperate folder. We also clean the environment of any values and dataframes that will not be useful going forward.

```{r}
# Load necessary library
library(tidyverse)

# Check if the list is named; if not, you might need to assign names
if (is.null(names(list_of_dataframes))) {
  warning("The list_of_dataframes is not named. Data frames will be saved with index-based names.")
  names(list_of_dataframes) <- paste0("dataframe_", seq_along(list_of_dataframes))
}

# Create a sub-directory for the CSV files if it doesn't already exist
dir.create("data/csv", showWarnings = FALSE, recursive = TRUE)

# Loop through each data frame in the list
for (df_name in names(list_of_dataframes)) {
  # Define the file path and name for each CSV within the data/csv_files directory
  file_path <- paste0("data/csv/", df_name, ".csv")

  # Save the data frame to a CSV file
  write_csv(list_of_dataframes[[df_name]], file_path)
}

# Inform the user that the operation is complete
cat("All data frames have been saved in the 'data/csv_files' directory with their respective names.\n")


```

A final clean before we work with our CSV files

```{r}
#CLEANING YAY
rm(conditions, traj_data,traj_labels, i, marker_names, traj_files, data_dir, df_name, file_path, traj_files)
```

# Pre-processing: NA's, choosing markers, trimming to 30 seconds

## NA checking

For the most accurate analysis we want to include the following markers: Head, both hands and elbows, and chest. Before proceeding we check for NA's to verify none of these markers have too many NAs.

```{r}
combined_df <- dplyr::bind_rows(list_of_dataframes) %>% 
  dplyr::ungroup()  

combined_df %>% 
  dplyr::summarise(Total_NAs = sum(is.na(x)))
combined_df %>% 
  dplyr::summarise(Total_NON_NAs = sum(!is.na(x)))

#NA
na_pre_gap <- combined_df %>%
  group_by(marker) %>%
  summarise(na_count = sum(is.na(x)))

#NON NA
non_na_pre_gap <-combined_df %>%
  group_by(marker) %>%
  summarise(non_na_count = sum(!is.na(x)))

print(na_pre_gap)
print(non_na_pre_gap)

rm(non_na_pre_gap, na_pre_gap)
```

```{r}
# Assuming list_of_dataframes is a list of dataframes

# Iterate over the dataframes in the list
for (df_name in names(list_of_dataframes)) {
  # Get the dataframe directly from the list
  df <- list_of_dataframes[[df_name]]

  # Identify columns with NAs
  na_columns <- colnames(df)[colSums(is.na(df)) > 0]

  # Select "marker" column and columns with NAs
  columns_to_summarize <- c("marker", na_columns)
  
  # Perform the operation and summarize
  result <- df %>%
    dplyr::select(all_of(columns_to_summarize)) %>%
    dplyr::group_by(marker) %>%
    dplyr::summarise(across(everything(), ~ sum(is.na(.)))) %>%
    dplyr::arrange(across("x"))

  # Print the result
  print(result)
}

rm(result, df, columns_to_summarize, df_name, na_columns)
```

### NA checking - head marker

We noticed that head_top didn't have a lot of NA's, so we checked whether or not it was the extra marker for A

```{r checking to see which markers B have}
  list_of_dataframes$group0_jointlead %>%
  dplyr::filter(subject == "B") %>%
  distinct(marker)

## Subject B has no head_top heheheheheee
```

head_top does not appear as a marker in the list, given subject B was only given 2 dots on their head and A was given two; therefore, head_top is the "missing" marker and we therefore cannot use it to compare subjects.

## Visualising the NAs

```{r}
# Assuming list_of_dataframes is a list of dataframes, each with 'names' and 'types' columns

# Combine all dataframes in list_of_dataframes into one dataframe
combined_df <- dplyr::bind_rows(list_of_dataframes, .id = "group")

# Identifying columns with NAs and processing
na_columns <- colnames(combined_df)[colSums(is.na(combined_df)) > 0]
columns_to_summarize <- c("marker", na_columns, "group", "condition")

# Summarize the number of NAs for each marker
result <- combined_df %>%
  dplyr::select(dplyr::all_of(columns_to_summarize)) %>%
  dplyr::group_by(group, marker, condition) %>%
  dplyr::summarise(across(everything(), ~ sum(is.na(.))), .groups = "drop") %>%
  dplyr::arrange(marker, condition)

# Plotting with facet wrap
p <- ggplot(result, aes(x = marker, y = x, fill = marker)) +
  geom_bar(stat = "identity", position = "dodge", show.legend = FALSE) +
  labs(title = "NA's in Combined Dataframes", x = "Marker", y = "Number of NA") +
  facet_wrap(~ condition) +
  coord_flip()

# Print the combined plot
print(p)
rm(p, result, columns_to_summarize, na_columns)
```

```{r}
# Now we can get the longest sequence of NAs for each marker
longest_na_seq <- combined_df %>% 
  group_by(condition, subject, marker) %>%
  summarise_at(
    vars(x, y, z),
    ~ max(rle(is.na(.))$lengths)
  )

# plot to check if it is acceptable
longest_na_seq %>% 
  ggplot(aes(x = marker, y = x, fill=marker, group=subject)) +
  geom_col(
    show.legend = FALSE
  ) +
  coord_flip() +
  facet_wrap(c(~subject, ~condition)) +
  labs(
    x = "Marker",
    y = "Longest NA sequence",
    title = "Longest NA sequence by marker"
  )
rm(longest_na_seq)
```

Unfortunately, the elbow markers have a lot of NA's. According to our plots, the head markers are consistently low in NA's, while the distribution of NA's for hands and chest is not consistent throughout the groups, we continue with checking the euclydian distance to further verify the validity of choosing said markers. However, the head_top is only present for participant A, and therefore we must choose either head_left or head_right. Since head_right has fewer NA's and the longest sequence is also smaller, we proceed with head_right

### Euclidean distance

```{r Euclidean distance plots for each marker}
# Iterate directly over the dataframes in list_of_dataframes
for (df in list_of_dataframes) {
  # Calculate the euclidean distance between each marker (using x, y, z)
  # We will do this by subject, marker, and axis
  marker_distances <- df %>% 
    dplyr::group_by(subject, marker) %>%
    dplyr::arrange(index) %>%
    dplyr::mutate(
      diff_x = x - dplyr::lag(x, 1),
      diff_y = y - dplyr::lag(y, 1),
      diff_z = z - dplyr::lag(z, 1)
    ) %>%
    dplyr::mutate(
      euclidean_distance = sqrt(diff_x^2 + diff_y^2 + diff_z^2)
    )

  # Plot the series for each marker, and see if anything stands out
  plot <- ggplot(marker_distances, aes(x = index, y = euclidean_distance)) +
    geom_line(aes(color = factor(marker)), linewidth = 1.25) +
    theme_minimal() +
    facet_wrap(~condition + subject) +
    labs(
      x = "Index",
      y = "Euclidean distance",
      title = "Euclidean distance from the previous frame by marker",
      subtitle = paste( df$group[1], "Condition:", df$condition[1])
    )
  
  # Print the plot
  print(plot)
}
rm(df, df_name, marker_distances, plot)
```

```{r euclidean_distance_selected_markers}
# Assuming list_of_dataframes is a list of dataframes

for (df in list_of_dataframes) {
  # Calculate the euclidean distance between each marker (using x, y, z)
  # We will do this by subject, marker, and axis
  marker_distances <- df %>% 
    dplyr::group_by(subject, marker) %>%
    dplyr::arrange(index) %>%
    dplyr::mutate(
      diff_x = x - dplyr::lag(x, 1),
      diff_y = y - dplyr::lag(y, 1),
      diff_z = z - dplyr::lag(z, 1)
    ) %>%
    dplyr::mutate(
      euclidean_distance = sqrt(diff_x^2 + diff_y^2 + diff_z^2)
    ) %>%
    # Filter only the specified markers
    dplyr::filter(marker %in% c("head_right", "hand_right", "hand_left", "chest"))

  # Plot the series for each marker, and see if anything stands out
  plot <- ggplot(marker_distances, aes(x = index, y = euclidean_distance)) +
    geom_line(aes(color = factor(marker)), linewidth = 1.25) +
    theme_minimal() +
    facet_wrap(~condition + subject) +
    labs(
      x = "Index",
      y = "Euclidean distance",
      title = "Euclidean distance from the previous frame by marker",
      subtitle = paste("Group:", df$group[1], "Condition:", df$condition[1])
    )
  
  # Print the plot
  print(plot)
}
rm(df, marker_distances, plot)
```

### Inspecting the raw data by plotting the x-coordinates

(inspecting to further validate the selection of markers -\> the markers chosen account for most of movement)

```{r for loop that plots x-coordinates for all markers in all groups}
## Making a for loop that plots x-coordinates for all markers in all groups
for (df in list_of_dataframes) {
 # Create ggplot
  plot <- ggplot(df, aes(x = x, y = marker)) +
    geom_point() +
    ggtitle(paste("Group:", df$group[1], "Condition:", df$condition[1]))
  
  # Print the plot
  print(plot)
}
rm(df, plot)
```

## Choosing markers

Before filling gaps, we specify the markers we wish to choose. As specified before, we choose chest, hands and head.

```{r}
# get the markers of interest
markers_of_interest <- c(
  "hand_right",
  "head_right",
  "hand_left",
  "chest"
)

# Apply the filter to each dataframe in list_of_dataframes
list_of_dataframes <- lapply(list_of_dataframes, function(df) {
  df %>% dplyr::filter(marker %in% markers_of_interest)
})
```

## Gap-filling

Before trimming, we gap-fill in order to account for all the NA's that might exist in the intervals of trimming.

```{r}
# Assuming markers_of_interest is defined and has at least 4 elements
# Assuming gap_fill_linear is a function that performs linear gap filling

for (i in seq_along(list_of_dataframes)) {
  # Access the dataframe
  df <- list_of_dataframes[[i]]

  # Extract a representative 'group' and 'condition' value (assuming they are consistent within each dataframe)
  group_value <- unique(df$group)[1]
  condition_value <- unique(df$condition)[1]

  # Iterate over selected markers
  for (sel_idx in 1:4) {
    # Plot before gap-filling
    plot_before <- df %>% 
      dplyr::filter(marker %in% markers_of_interest, marker == markers_of_interest[sel_idx]) %>%
      ggplot(aes(x = elapsed_time, y = x, color = subject)) +
      geom_line() +
      facet_wrap(~condition) +
      labs(
        x = "Elapsed time",
        y = "Marker X position",
        title = paste("Marker", markers_of_interest[sel_idx], "X position before gap filling"),
        subtitle = paste("Group:", group_value, " | ", "Condition:", condition_value)
      )
    print(plot_before)
    # Save the plot if needed
    # ggsave(...) - add the appropriate ggsave call here if needed

    # Apply the linear gap fill function to each column, by condition
    df <- df %>% 
      dplyr::group_by(condition, subject, marker) %>%
      dplyr::mutate(across(c(x, y, z), ~ gap_fill_linear(.)))

    # Update the dataframe in the list
    list_of_dataframes[[i]] <- df

    # Plot after gap-filling
    plot_after <- df %>% 
      dplyr::filter(marker %in% markers_of_interest, marker == markers_of_interest[sel_idx]) %>%
      ggplot(aes(x = elapsed_time, y = x, color = subject)) +
      geom_line() +
      facet_wrap(~condition) +
      labs(
        x = "Elapsed time",
        y = "Marker X position",
        title = paste("Marker", markers_of_interest[sel_idx], "X position after gap filling"),
        subtitle = paste("Group:", group_value, " | ", "Condition:", condition_value)
      )
    print(plot_after)
    # Save the plot if needed
    # ggsave(...) - add the appropriate ggsave call here if needed
  }
}

# At this point, list_of_dataframes is updated with the gap-filled data

# Combine all dataframes into a single dataframe
combined_df <- dplyr::bind_rows(list_of_dataframes, .id = "group")

rm(plot_after, plot_before, df, sel_idx, i, condition_value, group_value)
```

```{r}
# Assuming markers_of_interest is defined and has at least 4 elements
# Assuming gap_fill_linear is a function that performs linear gap filling

for (i in seq_along(list_of_dataframes)) {
  # Access the dataframe
  df <- list_of_dataframes[[i]]

  # Apply the linear gap fill function to each column, by condition, subject, and marker
  df <- df %>% 
    dplyr::group_by(condition, subject, marker)

  # Update the dataframe in the list
  list_of_dataframes[[i]] <- df

  # Create a combined plot for each group and condition, faceted by marker
  unique_groups <- unique(df$group)
  unique_conditions <- unique(df$condition)

  for (group in unique_groups) {
    for (condition in unique_conditions) {
      plot_combined <- df %>% 
        dplyr::filter(group == group, condition == condition, marker %in% markers_of_interest) %>%
        ggplot(aes(x = elapsed_time, y = x, color = subject)) +
        geom_line() +
        facet_wrap(~marker, nrow = 2, ncol = 2) +  # Arrange facets in a 2x2 grid by marker
        labs(
          x = "Elapsed time",
          y = "Marker X position",
          title = paste("Group:", group, "| Condition:", condition, "- Marker X Positions after Gap Filling")
        )
      print(plot_combined)
    }
  }
}
```

## NAs after gapfilling

```{r}
# Now, combined_df contains only the rows from all dataframes where marker matches the markers of interest
combined_df %>% 
  dplyr::summarise(Total_NAs = sum(is.na(x)))
combined_df %>% 
  dplyr::summarise(Total_NON_NAs = sum(!is.na(x)))

#NA
na_post_gap <- combined_df %>%
  group_by(marker) %>%
  summarise(na_count = sum(is.na(x)))

#NON NA
non_na_post_gap <-combined_df %>%
  group_by(marker) %>%
  summarise(non_na_count = sum(!is.na(x)))

print(na_post_gap)
print(non_na_post_gap)

rm(non_na_post_gap, na_post_gap)
```

## Trimming to 30 sec

Before proceeding we must trim the trajectories to accurately match the window of data collection - meaning, we must identify the 30 second window from which the t-pose starts.

Our original dataframes have a frame every 0,003rd second, so in order to save computational power, we simplify the dataframe for visualisation. In this case we will have points every half second.

```{r}
# Create a new list with processed dataframes without overwriting the original list
every_half_second_df_list <- lapply(list_of_dataframes, function(df) {
  df %>%
    group_by(subject, marker) %>%
    slice(seq(1, n(), by = 151)) %>%
    ungroup()
})

# Now, every_half_second_df_list contains the processed versions of the dataframes

```

Then we make 3d plots with included timeframe to identify the t-poses and thereby where our 30 second window starts.

```{r}
# Create an empty list to store the plots
plot_list <- list()

# Iterate through the simplified dataframes
for (i in seq_along(every_half_second_df_list)) {
  df_name <- names(every_half_second_df_list)[i]
  df <- every_half_second_df_list[[i]]
  
  # Create the base plot
  fig <- plot_ly(df, 
                 x = ~x, 
                 y = ~y, 
                 z = ~z, 
                 type = "scatter3d", 
                 mode = "markers", 
                 size = 2,
                 frame = ~elapsed_time,
                 marker = list(size = 4), ## Adjusting the marker size
                 color = ~subject)
  
  fig <- fig %>% plotly::layout(
    scene = list(
      xaxis = list(title = "X-axis", range = c(-800, 800)), 
      yaxis = list(title = "Y-axis", range = c(-800, 800)),
      zaxis = list(title = "Z-axis", range = c(0, 1800)),
      aspectmode = "manual",
      aspectratio = list(x = 1, y = 1, z = 1)
    ),
    xaxis = list(title = "X-axis"), 
    yaxis = list(title = "Y-axis"),
    zaxis = list(title = "Z-axis"))
  
  fig <- fig %>% ## adding and changing text
    plotly::layout(title = list(text = df_name, y = 0.9), 
                   font=list(size=15, family = "Times new roman"),
                   legend = list(title = list(text = "markers")))
  
  plot_list[[i]] <- fig
}

# Now plot_list contains all the plots for each simplified dataframe

# Save each plot in plot_list as an HTML file
for (i in seq_along(plot_list)) {
  plot <- plot_list[[i]]
  filename <- paste0("plot_", i, ".html")
  saveWidget(plot, file = filename)
}
```

```{r}
plot_list
rm(df, fig, plot, i, df_name, filename, current_df)
```

Now, we manually identify the values of elapsed_time that correspond to the beginning for each group and condition.

```{r}
start_time_df <- data.frame(
  group_and_condition = c("group0_jointlead",
                          "group0_leadfollow",
                          "group1_jointlead",
                          "group1_leadfollow",
                          "group12_jointlead",
                          "group12_leadfollow",
                          "group13_jointlead",
                          "group13_leadfollow",
                          "group2_jointlead",
                          "group2_leadfollow",
                          "group3_jointlead",
                          "group3_leadfollow",
                          "group4_leadfollow",
                          "group6_jointlead",
                          "group6_leadfollow",
                          "group8_leadfollow"),
  elapsed_time_at_start = as.numeric(c("17",
                            "35",
                            "12",
                            "50",
                            "33",
                            "28",
                            "37",
                            "94",
                            "18",
                            "31",
                            "12",
                            "42",
                            "37",
                            "14",
                            "29",
                            "52")
                            )
)
#We no longer need the simplified dataframe :)
rm(every_half_second_df_list)
```

Now we will iterate through all the group dataframes and pick the elapsed_time value associated.

```{r}
# Iterate through rows of start_time_df and extract subsets
for (i in 1:nrow(start_time_df)) {
  df_name <- start_time_df$group_and_condition[i]
  start_time <- start_time_df$elapsed_time_at_start[i]
  
  # Find the corresponding dataframe in list_of_dataframes, if it exists
  if (df_name %in% names(list_of_dataframes)) {
    # Access the dataframe directly from the list
    df <- list_of_dataframes[[df_name]]
    
    # Arrange the dataframe by elapsed_time
    df <- df %>% dplyr::arrange(elapsed_time)
    
    # Extract the subset based on the starting value
    starting_index <- which(df$elapsed_time == start_time)[1]
    ending_index <- which(df$elapsed_time == start_time + 30)[1]
    
    if (!is.na(starting_index) && !is.na(ending_index)) {
      # Update the original dataframe in the list with the subset
      list_of_dataframes[[df_name]] <- df[starting_index:ending_index, ]
    }
    # No else block needed, if indices are not found, the original dataframe remains unchanged
  }
  # No else block needed, if the dataframe does not exist in the list, nothing happens
}

# Now, list_of_dataframes contains the updated dataframes with the subsets

#cleaning up again! 
rm(df, df_name, ending_index, first_index, i, start_time, starting_index, start_time_df)
```

## Visualising markers' paths

We will iterate through our list of dataframes to see how the gap-fill and trajectory trimming has affected our data.

```{r}
# Assuming markers_of_interest is defined and has at least 4 elements

for (i in seq_along(list_of_dataframes)) {
  # Access the dataframe
  df <- list_of_dataframes[[i]]

  # Extract representative 'group' and 'condition' values
  group_value <- unique(df$group)[1]
  condition_value <- unique(df$condition)[1]

  # Filter for markers of interest and then create a single plot
  df_filtered <- df %>% dplyr::filter(marker %in% markers_of_interest)

  # Create one combined plot with facets for each marker
  plot_combined <- df_filtered %>% 
    ggplot(aes(x = elapsed_time, y = x, color = subject)) +
    geom_line() +
    facet_wrap(~marker, nrow = 2, ncol = 2) +  # Arrange facets only by marker
    labs(
      x = "Elapsed time",
      y = "Marker X position",
      title = paste("Markers X Positions"),
      subtitle = paste("Dataframe:", names(list_of_dataframes)[i])
    )
  print(plot_combined)

  # Save the plot if needed
  ggsave(
    plot_combined,
    filename = paste0(
      "./results/",
      names(list_of_dataframes)[i],
      "_group_",
      group_value,
      "_condition_",
      condition_value,
      "_x_position.png"),
    width = 12,
    height = 10,
    units = "cm",
    dpi = 300
  )
}

rm(group, group_value, i, unique_conditions, unique_groups, condition, condition_value, plot_combined, df, df_filtered)
```

It is clear the quality of the dataset differs immensely, and some groups have significantly more NA's than others.

## NA check post trim and gap-fill

```{r}
#overwriting the combined with the gap filled from the list
combined_df <- dplyr::bind_rows(list_of_dataframes) %>% 
  dplyr::ungroup()  

#Totals
combined_df %>% 
  dplyr::summarise(Total_NAs = sum(is.na(x)))

combined_df %>% 
  dplyr::summarise(Total_NON_NAs = sum(!is.na(x)))
#NA

na_post_gap <- combined_df %>%
  group_by(marker) %>%
  summarise(na_count = sum(is.na(x)))

#NON NA
non_na_post_gap <- combined_df %>%
  group_by(marker) %>%
  summarise(non_na_count = sum(!is.na(x)))

print(non_na_post_gap)
print(na_post_gap)

rm(non_na_post_gap, na_post_gap)
```

We still have a lot of NA's caused by inadequent registering of markers during experiment. After gap-filling the total NAs have gone from xxxx to 93280

\-\-\-\-\-\--

# ICA

## ICA-preprocessing

In order for ICA to work, our data must be exclusively numeric, meaning we will need to prep dataframes to include only our coordinates. The goal is to get a measure of the subjects movement per time, therefore we split our data into two: A and B. We also omit any NAs. This is subpar, but we have decided it is better to omit NAs entirely rather than apply an average throughout the missing rows - as this migth skew it in favour of looking more synchronised.

```{r}
list_of_dataframes_A <- list()
list_of_dataframes_B <- list()

# Get the names of the original dataframes
original_names <- names(list_of_dataframes)

for (i in seq_along(list_of_dataframes)) {
    df <- list_of_dataframes[[i]]
    df_name <- original_names[i]

    # Split the dataframe based on 'subject' and omit rows with NAs
    df_A <- na.omit(df[df$subject == 'A', ])
    df_B <- na.omit(df[df$subject == 'B', ])

    # Add the split and cleaned dataframes to their respective lists with modified names
    if(nrow(df_A) > 0) {
        list_of_dataframes_A[[paste(df_name, "A", sep = "_")]] <- df_A
    }
    if(nrow(df_B) > 0) {
        list_of_dataframes_B[[paste(df_name, "B", sep = "_")]] <- df_B
    }
}
rm(df, df_A, df_B, i, df_name)
```

Now that we have split our data, we need to convert it into a matrix with xyz coordinates where each row is a time-frame. In order to do this, we need to go back to a wider format, where each row is a single time point. This means each marker x y z will take up columns. We exclude elapsed_time, because it will be represented row-by-row. We also need to ungroup the dataframe, otherwise we can't remove columns. Furthermore, once changed to matrix, we have no choice but to impute NA or discard all rows with NAs, which is not viable.

```{r}
library(dplyr)

# Define a function to replace NAs with column means
replace_nas_with_column_means <- function(df) {
  df %>%
    mutate(across(everything(), ~ifelse(is.na(.), mean(., na.rm = TRUE), .)))
}

# Iterate over list_of_dataframes_A and replace NAs with column means
for (i in seq_along(list_of_dataframes_A)) {
  list_of_dataframes_A[[i]] <- list_of_dataframes_A[[i]] %>%
    ungroup() %>%
    select(-condition, -index, -subject, -group) %>%
    gather(key, value, -elapsed_time, -marker) %>%
    unite(col = "new_col", marker, key, remove = TRUE) %>%
    spread(key = new_col, value = value) %>%
    arrange(elapsed_time) %>%
    replace_nas_with_column_means()
}

# Iterate over list_of_dataframes_B and replace NAs with column means
for (i in seq_along(list_of_dataframes_B)) {
  list_of_dataframes_B[[i]] <- list_of_dataframes_B[[i]] %>%
    ungroup() %>%
    select(-condition, -index, -subject, -group) %>%
    gather(key, value, -elapsed_time, -marker) %>%
    unite(col = "new_col", marker, key, remove = TRUE) %>%
    spread(key = new_col, value = value) %>%
    arrange(elapsed_time) %>%
    replace_nas_with_column_means()
}
rm(i)
```

Now we are ready to convert to matrix:

```{r}
library(dplyr)

# Function to convert a dataframe to a matrix for ICA
convert_df_to_matrix <- function(df) {
    # Ensure the dataframe is sorted by elapsed_time
    df_sorted <- df %>% arrange(elapsed_time)

    # Select only numeric columns (except 'elapsed_time' if it's not numeric)
    # and keep 'elapsed_time' as the first column
    numeric_cols <- sapply(df_sorted, is.numeric)
    df_matrix <- df_sorted %>% select(elapsed_time, where(is.numeric))

    return(as.matrix(df_matrix))
}

# Convert each dataframe in list_of_dataframes_A to a matrix
matrices_A <- lapply(list_of_dataframes_A, convert_df_to_matrix)

# Convert each dataframe in list_of_dataframes_B to a matrix
matrices_B <- lapply(list_of_dataframes_B, convert_df_to_matrix)

```

```{r}
# Check for NAs in matrices_A
any(is.na(unlist(matrices_A)))

# Check for NAs in matrices_B
any(is.na(unlist(matrices_B)))

```

## Running ICA

Though we may lose some data-complexity, we decide to extract only 1 component.

```{r}
# Function to apply ICA on a matrix
apply_ica <- function(matrix_data, n_comp) {
  # Assuming the first column is 'elapsed_time' and should not be included in ICA
  matrix_for_ica <- matrix_data[, -1]  # Exclude 'elapsed_time'
  
  # Run ICA
  if(ncol(matrix_for_ica) >= n_comp) {
    ica_result <- fastICA(matrix_for_ica, n.comp = n_comp,alg.typ = "parallel", fun = "logcosh", alpha = 1,
             method = "R", row.norm = FALSE, maxit = 200,
             tol = 0.0001, verbose = TRUE)
    return(ica_result)
  } else {
    warning(paste("Not enough columns in matrix to extract", n_comp, "components"))
    return(NULL)
  }
}

# Apply ICA on matrices in list_of_dataframes_A
ica_results_A <- lapply(matrices_A, apply_ica, n_comp = 1)  # Adjust n.comp as needed


# Apply ICA on matrices in list_of_dataframes_B
ica_results_B <- lapply(matrices_B, apply_ica, n_comp = 1)  # Adjust n.comp as needed
rm(list_of_dataframes_A, list_of_dataframes_B)
```

```{r}
# Extracting the independent components
component_list_A <- lapply(ica_results_A, function(ica) ica$S)
component_list_B <- lapply(ica_results_B, function(ica) ica$S)

rm(ica_results_A, ica_results_B)
```

```{r}
library(ggplot2)

# Visualizing the first component of the first subject in list A
component_to_visualize_A <- component_list_A[[1]]  # Adjust the index as needed

# Creating a time series plot for Subject A
ggplot(data.frame(time = 1:nrow(component_to_visualize_A), value = component_to_visualize_A[, 1]), aes(x = time, y = value)) +
  geom_line(size = 1) +  # Adjust the size for line thickness
  theme_minimal() +
  labs(title = "Independent Component - Subject A", x = "Time", y = "Component Value")

# Visualizing the first component of the first subject in list B
component_to_visualize_B <- component_list_B[[1]]  # Adjust the index as needed

# Creating a time series plot for Subject B
ggplot(data.frame(time = 1:nrow(component_to_visualize_B), value = component_to_visualize_B[, 1]), aes(x = time, y = value)) +
  geom_line(size = 1)+
  theme_minimal() +
  labs(title = "Independent Component - Subject B", x = "Time", y = "Component Value")


rm(component_to_visualize_A, component_to_visualize_B)
```

# DTW

```{r}
## limit reached
dtw_result <- dtw::dtw(ic_A$group0_jointlead_A, ic_B$group0_jointlead_B, keep = TRUE) ## min computer siger limit reached, so we are missing some computational strength. Jeg tror sagtens man kan køre den, hvis man f.eks. tager de 10 første sekunder - men vi skal jo gerne have alle 30 sekunder med 

# Access the DTW distance
dtw_distance <- dtw_result$distance

# Print the DTW distance
print(paste("DTW Distance:", dtw_distance))
```

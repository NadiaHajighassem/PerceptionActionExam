method = "R", row.norm = FALSE, maxit = 200,
tol = 0.0001, verbose = TRUE)
a <- fastICA(x, 2, alg.typ = "parallel", fun = "logcosh", alpha = 1,
method = "R", row.norm = FALSE, maxit = 200,
tol = 0.0001, verbose = TRUE)
a
par(mfrow = c(1, 2))  # plot 2 components
for (i in 1:2) {
plot(a$S[, i], type = "l", main = paste("Independent Component", i), ylab = "Amplitude", xlab = "Time")
}
# we want to do a cross correlation analysis
# we know there are always two subjects, and the
# marker labels start with the subject (A or B)
# we want to cross correlate between the same marker for
# subject A and subject B
# set the maximum lag in samples. e.g. 300 samples is 1 second
max_lag <- 900 # correlate with +/- 3 seconds
# define an empty list to store the results
xcor_results <- list()
for (marker in markers_of_interest) {
# get the data for the marker
marker_data <- selected_traj_data %>%
dplyr::filter(marker == marker)
# get the unique conditions
conds <- unique(marker_data$condition)
# now we can do the cross correlation analysis
for (cond in conds) {
# get the data for the condition
cond_data <- marker_data %>%
dplyr::filter(condition == cond)
# now we can do the cross correlation analysis
# we will do this for each axis
for (axis in c("x", "y", "z")) {
results <- ccf(
x = cond_data[cond_data$subject == "A", axis],
y = cond_data[cond_data$subject == "B", axis],
na.action = na.omit,
plot = FALSE,
lag.max = max_lag
)
# make a tibble with the results
results <- tibble(
lagv = results$lag,
acfv = results$acf,
marker = marker,
condition = cond,
axis = axis
)
xcor_results[[length(xcor_results) + 1]] <- results
}
}
}
# let's put all the acf results into a single tibble
xcor_results <- do.call(bind_rows, xcor_results)
# now we can plot the results for each lag point
xcor_results %>%
ggplot(aes(x = lagv, y = acfv, color = axis)) +
geom_point() +
theme_minimal() +
facet_wrap(c(~condition, ~marker)) +
labs(
x = "Lag",
y = "Autocorrelation",
title = "Autocorrelation by lag"
)
# save the plot
ggsave(
filename = "./results/autocorrelation_by_lag.png",
width = 10,
height = 10,
units = "cm",
dpi = 300
)
# let's also get the min and max autocorrelation for each condition and marker
xcor_results %>%
group_by(condition, marker, axis) %>%
summarise(
min = min(acfv),
max = max(acfv),
lag_min = lagv[which.min(acfv)],
lag_max = lagv[which.max(acfv)]
)
# we want to do a cross correlation analysis
# we know there are always two subjects, and the
# marker labels start with the subject (A or B)
# we want to cross correlate between the same marker for
# subject A and subject B
# set the maximum lag in samples. e.g. 300 samples is 1 second
max_lag <- 900 # correlate with +/- 3 seconds
# define an empty list to store the results
xcor_results <- list()
for (marker in markers_of_interest) {
# get the data for the marker
marker_data <- a %>%
dplyr::filter(marker == marker)
# get the unique conditions
conds <- unique(marker_data$condition)
# now we can do the cross correlation analysis
for (cond in conds) {
# get the data for the condition
cond_data <- a %>%
dplyr::filter(condition == cond)
# now we can do the cross correlation analysis
# we will do this for each axis
for (axis in c("x", "y", "z")) {
results <- ccf(
x = cond_data[cond_data$subject == "A", axis],
y = cond_data[cond_data$subject == "B", axis],
na.action = na.omit,
plot = FALSE,
lag.max = max_lag
)
# make a tibble with the results
results <- tibble(
lagv = results$lag,
acfv = results$acf,
marker = marker,
condition = cond,
axis = axis
)
xcor_results[[length(xcor_results) + 1]] <- results
}
}
}
## Plotting
par(mfrow = c(1, 2))  # plot 2 components
for (i in 1:2) {
plot(a$S[, i], type = "l", main = paste("Independent Component", i), ylab = "Amplitude", xlab = "Time")
}
## We should try different functions
a <- fastICA(x, 2, alg.typ = "parallel", fun = "logcosh", alpha = 1,
method = "R", row.norm = FALSE, maxit = 200,
tol = 0.0001, verbose = TRUE)
## Plotting
par(mfrow = c(1, 2))  # plot 2 components
for (i in 1:2) {
plot(a$S[, i], type = "l", main = paste("Independent Component", i), ylab = "Amplitude", xlab = "Time")
}
pairs(a , main="FastICA")
# Assuming x is your input data
# You may need to modify this depending on the structure of your data
# Create a scatter plot of the first two dimensions of the data
plot(x[, 1], x[, 2], main = "Original Data", xlab = "Dimension 1", ylab = "Dimension 2", pch = 16, col = "blue")
# Add labels for each point (optional)
text(x[, 1], x[, 2], labels = 1:nrow(x), pos = 3, col = "red")
# Add grid lines (optional)
abline(h = 0, v = 0, col = "gray", lty = 2)
# Add legend or additional information if necessary
legend("topright", legend = c("Data Points"), col = c("blue"), pch = 16)
# Display the plot
plot(x)
par(mfrow = c(1, 2))  # Set up a 1x2 plotting grid for two components
# Plot the original data before applying ICA
for (i in 1:2) {
plot(x[, i], type = "l", main = paste("Original Data Dimension", i), ylab = "Amplitude", xlab = "Time")
}
# Reset the plotting layout to default
par(mfrow = c(1, 1))
par(mfrow = c(1, 2))  # Set up a 1x2 plotting grid for two components
# Plot the original data before applying ICA
for (i in 1:2) {
plot(x[, i], type = "l", main = paste("Original Data Dimension", i), ylab = "Amplitude", xlab = "Time")
}
par(mfrow = c(1, 1))
par(mfrow = c(1, 2))  # Set up a 1x2 plotting grid for two components
# Plot the original data before applying ICA
for (i in 1:2) {
plot(x[, i], type = "l", main = paste("Original Data Dimension", i), ylab = "Amplitude", xlab = "Time")
}
## We should try different functions
a <- fastICA(x, 2, alg.typ = "parallel", fun = "logcosh", alpha = 1,
method = "R", row.norm = FALSE, maxit = 200,
tol = 0.0001, verbose = TRUE)
## side note: neg-entropy is a way of measuring how much a distribution deviates from a Gaussian distribution. We want to maximize neg-entropy because it maximizes independence, which is the whole purpose of ICA.
## Plotting
par(mfrow = c(1, 2))  # plot 2 components
for (i in 1:2) {
plot(a$S[, i], type = "l", main = paste("Independent Component", i), ylab = "Amplitude", xlab = "Time")
}
## Setup chunk
knitr::opts_chunk$set(echo = TRUE, include = TRUE, message = FALSE, warning = FALSE)
pacman::p_load(
"XML",
"tidyverse",
"fs",
"assertthat",
"stringi",
"dtw",
"RTransferEntropy",
"signal",
"conflicted",
"Rcpp",
"future",
"fastICA"
)
## Making sure we are in the right directory
wd <- getwd()
if (basename(wd) != "PerceptionActionExam") {
setwd("./PerceptionActionExam")
}
# set the directory for the data
# note, path_home() will return the path to your home directory
# your home directory is the one that contains your documents, downloads, etc.
data_dir <- path_home() %>%
path("Documents", "GitHub", "PerceptionActionExam", "data", "tsvs")
# set your study group
group_number <- 8
# The available conditions and their start and end frame indices
# to use the whole file, just set the value for the condition to c(NA, NA)
conditions <- list(
jointlead = c(NA, NA),
followlead = c(NA, NA),
leadfollow = c(NA, NA),
custom = c(NA, NA)
)
process_qtm_tsv <- function(
data_file,
condition_regex = "group[0-9]+_([^_\\.]+).*", # a regular expression used to search for patterns
null_value = "NA"
) {
"This function processes a QTM TSV file and reads it into a dataframe.
You will get both the trajectory data (dataframe) as well as metadata.
Args:
data_file (str): The path to the QTM TSV file.
condition_regex (str): A regex to extract the condition from the file name.
null_value (str): The value in the files that represents a missing measurement.
Returns:
A list with two elements:
- data: The trajectory data as a dataframe.
- metadata: A list with the metadata.
The metadata contains the following elements:
- condition: The condition of the data.
- frequency: The frequency (Hz) of the data.
- marker_count: The number of markers.
- frame_count: The number of frames.
- marker_names: The names of the markers.
"
message(paste("Processing", data_file))
# get the condition
cond <- stri_match_last_regex(data_file, condition_regex)[2]
# make condition lowercase
cond <- tolower(cond)
message(paste("Condition:", cond))
# read in the data
dat <- readLines(data_file)
# now get other relevant metadata
# get frequency
freq <- stri_match_first_regex(dat, "^FREQUENCY.*")
freq <- freq[!is.na(freq)]
# get marker count
marker_count <- stri_extract_first_regex(dat, "^NO_OF_MARKERS.*")
marker_count <- marker_count[!is.na(marker_count)]
marker_count_value <- as.integer(stri_split_fixed(marker_count, "\t")[[1]][2])
# get frame count
frame_count <- stri_extract_first_regex(dat, "^NO_OF_FRAMES.*")
frame_count <- frame_count[!is.na(frame_count)]
frame_count_value <- as.integer(stri_split_fixed(frame_count, "\t")[[1]][2])
# get marker names
marker_names <- stri_extract_first_regex(dat, "^MARKER_NAMES.*")
marker_names <- marker_names[!is.na(marker_names)]
marker_names_values <- stri_split_fixed(
marker_names,
"\t"
)[[1]][1:marker_count_value + 1]
message("File information:")
message(paste(freq, "Hz", "frequency"))
message(paste(marker_count_value, "markers"))
message(paste(frame_count_value, "frames"))
# now just keep the tracking information
dat <- stri_extract_first_regex(dat, "^[0-9]+\t.*")
dat <- dat[!is.na(dat)]
# now ensure the number of frames is correct
# this is the number of lines in the data
assertthat::assert_that(
length(dat) == frame_count_value,
msg = paste(
"Number of frames is not correct, found:",
length(dat),
"expected:",
frame_count_value)
)
# ensure the number of markers is correct
# this is 3 columns per marker, plus index and time
num_found_markers <- length(stri_split_fixed(dat[[1]], "\t")[[1]])
assertthat::assert_that(
num_found_markers == marker_count_value * 3 + 2,
msg = paste(
"Number of markers is not correct, found:",
num_found_markers,
"expected:",
marker_count_value * 3 + 2)
)
message(paste("File has", length(dat), "frames"))
message(paste("File has", marker_count_value, "markers"))
message("Creating data frame...")
col_names <- c(
"index",
"elapsed_time",
paste0(
rep(marker_names_values, each = 3),
c("_x", "_y", "_z")
)
)
# now we need to create a data frame
# split each line by tab
dat <- stri_split_fixed(dat, "\t", simplify = TRUE)
# set the column names
colnames(dat) <- col_names
# and then convert to a data frame
dat <- as_tibble(dat)
# now we need to replace the null values with NA
dat[dat == null_value] <- NA
# and convert to numeric
dat <- mutate_all(dat, as.numeric)
metadata <- list(
condition = cond,
frequency = freq,
marker_count = marker_count,
frame_count = frame_count,
marker_names = marker_names
)
# return the data and metadata
return(list(data = dat, metadata = metadata))
}
gap_fill_linear <- function(x) {
"This function does a linear gap fill for a vector.
Only columns with at least 2 non-NA values will be gap filled.
Args:
x (vector): The vector to gap fill.
Returns:
The gap filled vector.
"
# get the indices of the NA values
na_indices <- which(is.na(x))
# get the indices of the non-NA values
non_na_indices <- which(!is.na(x))
if (length(na_indices) == 0) {
# if there are no NA values, just return the vector
return(x)
}
if (length(non_na_indices) < 2) {
# if there are less than 2 non-NA values, we can't do a linear interpolation
return(x)
}
# get the values of the non-NA indices
non_na_values <- x[non_na_indices]
# get the values of the NA indices
na_values <- x[na_indices]
# now we can do a linear interpolation
na_values <- approx(
x = non_na_indices,
y = non_na_values,
xout = na_indices,
method = "linear"
)$y
# now we can replace the NA values with the interpolated values
x[na_indices] <- na_values
# and return the vector
return(x)
}
# load the labels from the XML file
# load the XML file
xmlfile <- xmlParse("PerAct23_LabelList.xml")
# get the labels, which are in the following format:
# <QTM_Label_List_Ver_1.00>
#     <Trajectories>
#         <Trajectory>
#             <Name>A_head_top</Name>
#             <Color R="0" G="147" B="0"/>
#         </Trajectory>
#     </Trajectories>
# </QTM_Label_List_Ver_1.00>
# get the trajectory names
traj_names <- xpathSApply(xmlfile, "//Trajectory/Name", xmlValue)
# get the trajectory colors
traj_colors <- xpathSApply(xmlfile, "//Trajectory/Color", xmlAttrs)
# convert the colors to hex
traj_colors <- rgb(
as.numeric(traj_colors[1,]),
as.numeric(traj_colors[2,]),
as.numeric(traj_colors[3,]),
alpha = 255,
maxColorValue = 255
)
# combine the names and colors into a data frame
traj_labels <- data.frame(
traj_names,
traj_colors,
stringsAsFactors = FALSE
)
rm(xmlfile, traj_names, traj_colors)
## this loads in all the files
traj_files <- fs::dir_ls(data_dir, regexp = "\\.tsv$")
# load the trajectory data, we want all TSVs with the group number in the name
# get the files
traj_files <- fs::dir_ls(data_dir, regexp = paste0("group", group_number, "_.*\\.tsv$"))
# load the data
traj_data <- lapply(traj_files, process_qtm_tsv)
# now we need to combine the data into a single data frame
# first we need to add the condition and group to each data frame
traj_data <- lapply(traj_data, function(x) {
x$data$condition <- x$metadata$condition
x$data$group <- paste0("group", group_number)
return(x)
})
# now we can combine the data
traj_data <- do.call(bind_rows, lapply(traj_data, `[[`, "data"))
# make the condition and group factors
traj_data$condition <- factor(traj_data$condition)
traj_data$group <- factor(traj_data$group)
# take a look at the data
head(traj_data)
# let's also make sure that all of the marker names are the same
# we can do this by getting the unique marker names
marker_names <- unique(traj_data %>% select(contains("_x")) %>% names() %>% stri_replace_last_regex("_x", ""))
# now we can check that all of the marker names are the same
assertthat::assert_that(
all(marker_names == traj_labels$traj_names),
msg = "Not all marker names are the same"
)
# let's make the data long format so we can easily group by subject or marker
traj_data <- traj_data %>%
pivot_longer(
cols = contains("_x") | contains("_y") | contains("_z"),
cols_vary = "slowest",
names_to = "marker",
values_to = "value"
) %>%
mutate(
subject = stri_replace_first_regex(marker, "^([AB])_.*", "$1"),
axis = stri_extract_last_regex(marker, "[xyz]$"),
marker = stri_replace_first_regex(marker, "^[AB]_([a-zA-Z_]+)_[xyz]$", "$1")
)
# move axes to columns
traj_data <- traj_data %>%
pivot_wider(
names_from = axis,
values_from = value
)
# Making sure that we have all of the different markers HEHEHEEH HI KAT
unique(traj_data$marker)
#traj_data$marker <- factor(traj_data$marker, levels = marker_names) ## i cant remember why this is here, but i think it is important later.
# We want to crop the data for each condition
# let's get all the recorded conditions
recorded_conditions <- unique(traj_data$condition)
for (cond in recorded_conditions) {
# get the start and end frame for the condition
start_frame <- conditions[[cond]][1]
if (is.na(start_frame)) start_frame <- 1
end_frame <- conditions[[cond]][2]
if (is.na(end_frame)) end_frame <- max(traj_data[traj_data$condition == cond, "index"])
# crop the data
traj_data <- traj_data %>%
dplyr::filter(condition == cond & index >= start_frame & index <= end_frame | condition != cond)
}
# select min and max indices by condition
traj_data %>%
group_by(condition) %>%
summarise(
min_index = min(index),
max_index = max(index))
# report observations per condition
traj_data %>%
group_by(condition, subject, marker) %>%
summarise(
n_obs = n()
) %>%
print(n = 100)
## Filtering out custom condition
traj_data <- traj_data %>%
dplyr::filter(condition %in% c("leadfollow", "followlead")) ## a bit confused why this works
## Checking to see if the filtering worked :)
traj_data %>%
distinct(condition)
# we want to check for large jumps in the data
# this indicates potential label errors
# we will do this by calculating the distance between each marker for each time point
# of course, by condition
# calculate the euclidean distance between each marker (using x, y, z)
# we will do this by condition, subject, marker and axis
marker_distances <- traj_data %>%
group_by(condition, subject, marker) %>%
arrange(index) %>%
mutate(
diff_x = x - dplyr::lag(x, 1),
diff_y = y - dplyr::lag(y, 1),
diff_z = z - dplyr::lag(z, 1)
)
# now we can calculate the euclidean distance per maker
marker_distances <- marker_distances %>%
mutate(
euclidean_distance = sqrt(diff_x^2 + diff_y^2 + diff_z^2)
)
# now we can plot the series for each marker, and see if anything stands out
marker_distances %>%
ggplot(aes(x = index, y = euclidean_distance)) +
geom_line(aes(color = factor(marker)), linewidth=1.25) +
theme_minimal() +
facet_wrap(c(~condition, ~subject)) +
labs(
x = "Index",
y = "Euclidean distance",
title = "Euclidean distance from previous frame by marker"
)
# save the plot
ggsave(
filename = "./results/euclidean_distance_by_marker.png",
width = 10,
height = 10,
units = "cm",
dpi = 300
)
